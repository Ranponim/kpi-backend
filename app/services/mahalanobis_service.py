"""
ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ JavaScriptì˜ calculateMahalanobisDistance í•¨ìˆ˜ë¥¼ Pythonìœ¼ë¡œ ë²ˆì—­í•œ
MahalanobisAnalysisService í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import logging
import numpy as np
import scipy.stats as stats
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass

from ..models.mahalanobis import (
    KpiDataInput,
    AnalysisOptionsInput,
    AbnormalKpiDetail,
    ScreeningAnalysis,
    DrilldownAnalysis,
    AnalysisResult,
    MahalanobisAnalysisResult,
    validate_kpi_data,
    log_analysis_request
)
from ..utils.cache_manager import get_cache_manager

logger = logging.getLogger(__name__)


@dataclass
class StatisticalTestResult:
    """í†µê³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    test_name: str
    statistic: float
    p_value: float
    significant: bool
    interpretation: str
    effect_size: Optional[float] = None
    confidence_interval: Optional[Tuple[float, float]] = None


class MahalanobisAnalysisService:
    """
    ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ë¶„ì„ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤

    JavaScriptì˜ calculateMahalanobisDistance í•¨ìˆ˜ë¥¼ Pythonìœ¼ë¡œ ë²ˆì—­í•œ ë²„ì „ì…ë‹ˆë‹¤.
    """

    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        self.cache_manager = get_cache_manager()

    @property
    def cached_calculate(self):
        """ìºì‹œëœ calculate_mahalanobis_distance í•¨ìˆ˜"""
        return self.cache_manager.cached(ttl=1800)(self.calculate_mahalanobis_distance_original)

    def calculate_mahalanobis_distance(
        self,
        kpi_data: KpiDataInput,
        options: AnalysisOptionsInput
    ) -> MahalanobisAnalysisResult:
        """
        ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ê³„ì‚° ë° í†µê³„ ë¶„ì„ ìˆ˜í–‰ (ìºì‹œ ì§€ì›)

        ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•´ 30ë¶„ ë™ì•ˆ ìºì‹œëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        # ìºì‹œ í‚¤ ìƒì„±ì„ ìœ„í•œ í•´ì‹œ
        import hashlib
        import json

        # ì…ë ¥ ë°ì´í„°ì˜ í•´ì‹œ ìƒì„± (ìºì‹œ í‚¤ë¡œ ì‚¬ìš©)
        cache_data = {
            "kpi_data": kpi_data.kpi_data,
            "timestamps": kpi_data.timestamps,
            "period_labels": kpi_data.period_labels,
            "threshold": options.threshold,
            "sample_size": options.sample_size,
            "significance_level": options.significance_level
        }

        cache_key = hashlib.md5(
            json.dumps(cache_data, sort_keys=True, default=str).encode()
        ).hexdigest()

        # ìºì‹œ ì¡°íšŒ
        cached_result = self.cache_manager.cache.get(f"mahalanobis:{cache_key}")
        if cached_result is not None:
            self.logger.info(f"ìºì‹œ íˆíŠ¸: ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ê²°ê³¼ ë°˜í™˜")
            # ìºì‹œëœ ë°ì´í„°ê°€ ë¬¸ìì—´ì¸ ê²½ìš° JSON íŒŒì‹± í›„ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
            if isinstance(cached_result, str):
                import json
                try:
                    data_dict = json.loads(cached_result)
                    return MahalanobisAnalysisResult(**data_dict)
                except (json.JSONDecodeError, ValueError) as e:
                    self.logger.warning(f"ìºì‹œ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}, ì¬ê³„ì‚° ìˆ˜í–‰")
                    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìºì‹œ ì‚­ì œí•˜ê³  ì¬ê³„ì‚°
                    self.cache_manager.cache.delete(f"mahalanobis:{cache_key}")
            elif isinstance(cached_result, dict):
                return MahalanobisAnalysisResult(**cached_result)
            else:
                # ì´ë¯¸ ì˜¬ë°”ë¥¸ ê°ì²´ì¸ ê²½ìš°
                return cached_result

        # ìºì‹œ ë¯¸ìŠ¤: ê³„ì‚° ìˆ˜í–‰
        self.logger.info(f"ìºì‹œ ë¯¸ìŠ¤: ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ê³„ì‚° ì‹œì‘")
        result = self.calculate_mahalanobis_distance_original(kpi_data, options)

        # ê²°ê³¼ ìºì‹± (30ë¶„ TTL)
        self.cache_manager.cache.set(f"mahalanobis:{cache_key}", result, ttl=1800)

        return result

    def calculate_mahalanobis_distance_original(
        self,
        kpi_data: KpiDataInput,
        options: AnalysisOptionsInput
    ) -> MahalanobisAnalysisResult:
        """
        ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ê³„ì‚° ë° í†µê³„ ë¶„ì„ ìˆ˜í–‰ (ì›ë³¸ êµ¬í˜„)

        Args:
            kpi_data: KPI ë°ì´í„° ì…ë ¥
            options: ë¶„ì„ ì˜µì…˜

        Returns:
            MahalanobisAnalysisResult: ë¶„ì„ ê²°ê³¼

        Raises:
            ValueError: ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨ ì‹œ
            RuntimeError: ë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ
        """
        start_time = datetime.utcnow()

        try:
            # ì…ë ¥ ë°ì´í„° ê²€ì¦
            if not validate_kpi_data(kpi_data.kpi_data):
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ KPI ë°ì´í„°ì…ë‹ˆë‹¤")

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
            total_data_points = sum(len(values) for values in kpi_data.kpi_data.values())
            estimated_memory_mb = (total_data_points * 8 * 3) / (1024 * 1024)  # float64 * 3 arrays

            if estimated_memory_mb > 100:  # 100MB ì´ìƒ ì˜ˆìƒ ì‹œ ê²½ê³ 
                self.logger.warning(f"ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì˜ˆìƒ: {estimated_memory_mb:.1f}MB")
            elif estimated_memory_mb > 500:  # 500MB ì´ìƒ ì‹œ ì—ëŸ¬
                raise RuntimeError(f"ë°ì´í„° ê·œëª¨ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤: {estimated_memory_mb:.1f}MB")

            # ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ëŒ€í•œ ë°°ì¹˜ ì²˜ë¦¬ ì „ëµ
            if total_data_points > 5000:
                self.logger.info("ëŒ€ìš©ëŸ‰ ë°ì´í„° ê°ì§€: ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë“œë¡œ ì „í™˜")
                # ë°°ì¹˜ í¬ê¸° ê³„ì‚° (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê³ ë ¤)
                batch_size = min(1000, max(100, total_data_points // 10))
                self.logger.info(f"ë°°ì¹˜ í¬ê¸°: {batch_size} ë°ì´í„° í¬ì¸íŠ¸")

            # ê³„ì‚° ì„±ëŠ¥ ê²€ì¦
            if options.sample_size > 50 and len(kpi_data.kpi_data) > 20:
                self.logger.info("ë³µì¡í•œ ê³„ì‚°ì´ ì˜ˆìƒë©ë‹ˆë‹¤. ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤")

            # ë¶„ì„ ìš”ì²­ ë¡œê¹…
            log_analysis_request(kpi_data, options)

            self.logger.info("ğŸ§® ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ê³„ì‚° ì‹œì‘", extra={
                "kpi_count": len(kpi_data.kpi_data),
                "total_data_points": sum(len(values) for values in kpi_data.kpi_data.values())
            })

            # 1ì°¨ ìŠ¤í¬ë¦¬ë‹: ì¢…í•© ê±´ê°• ìƒíƒœ ì§„ë‹¨
            screening_result = self._perform_screening_analysis(kpi_data, options)

            # 2ì°¨ ì‹¬ì¸µ ë¶„ì„: Top-N KPIì— ëŒ€í•œ í†µê³„ í…ŒìŠ¤íŠ¸
            drilldown_result = self._perform_drilldown_analysis(
                kpi_data, screening_result.abnormal_kpis, options
            )

            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            analysis_result = AnalysisResult(
                totalKpis=screening_result.total_kpis,
                abnormalKpis=screening_result.abnormal_kpis,
                abnormalScore=screening_result.score,
                alarmLevel=screening_result.status,
                analysis={
                    "screening": {
                        "status": screening_result.status,
                        "score": screening_result.score,
                        "threshold": options.threshold,
                        "description": screening_result.description
                    },
                    "drilldown": {
                        "statisticalAnalysis": drilldown_result.statistical_analysis,
                        "summary": drilldown_result.summary
                    }
                }
            )

            processing_time = (datetime.utcnow() - start_time).total_seconds()

            result = MahalanobisAnalysisResult(
                data=analysis_result,
                processing_time=processing_time
            )

            self.logger.info("âœ… ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ê³„ì‚° ë° í†µê³„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ", extra={
                "processing_time": processing_time,
                "abnormal_kpis_count": len(screening_result.abnormal_kpis),
                "alarm_level": screening_result.status
            })

            return result

        except Exception as e:
            processing_time = (datetime.utcnow() - start_time).total_seconds()
            self.logger.error(f"âŒ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ê³„ì‚° ì‹¤íŒ¨: {e}", exc_info=True)

            # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
            error_result = MahalanobisAnalysisResult(
                success=False,
                message=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                data=AnalysisResult(
                    totalKpis=len(kpi_data.kpi_data) if kpi_data.kpi_data else 0,
                    abnormalKpis=[],
                    abnormalScore=0.0,
                    alarmLevel="error",
                    analysis={
                        "screening": {
                            "status": "error",
                            "score": 0.0,
                            "threshold": options.threshold,
                            "description": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
                        },
                        "drilldown": {
                            "statisticalAnalysis": [],
                            "summary": {"error": str(e)}
                        }
                    }
                ),
                processing_time=processing_time
            )

            return error_result

    def _perform_screening_analysis(
        self,
        kpi_data: KpiDataInput,
        options: AnalysisOptionsInput
    ) -> ScreeningAnalysis:
        """
        1ì°¨ ìŠ¤í¬ë¦¬ë‹ ë¶„ì„ ìˆ˜í–‰

        Args:
            kpi_data: KPI ë°ì´í„°
            options: ë¶„ì„ ì˜µì…˜

        Returns:
            ScreeningAnalysis: ìŠ¤í¬ë¦¬ë‹ ë¶„ì„ ê²°ê³¼
        """
        kpi_count = len(kpi_data.kpi_data)
        abnormal_kpis = []

        # ê° KPIì— ëŒ€í•´ ë³€í™”ìœ¨ ê³„ì‚° ë° ì„ê³„ì¹˜ íŒì •
        for kpi_name, values in kpi_data.kpi_data.items():
            if values and len(values) >= 2:
                abnormal_kpi = self._analyze_single_kpi(kpi_name, values, options)
                if abnormal_kpi:
                    abnormal_kpis.append(abnormal_kpi)

        # ì¢…í•© ì´ìƒ ì ìˆ˜ ê³„ì‚°
        abnormal_score = len(abnormal_kpis) / kpi_count if kpi_count > 0 else 0.0

        # ì„ê³„ì¹˜ ê¸°ë°˜ ì•ŒëŒ íŒì •
        alarm_level = self._determine_alarm_level(abnormal_score)

        description = "ë¹„ì •ìƒ íŒ¨í„´ ê°ì§€ë¨" if abnormal_score > options.threshold else "ì •ìƒ ë²”ìœ„ ë‚´"

        return ScreeningAnalysis(
            status=alarm_level,
            score=abnormal_score,
            threshold=options.threshold,
            description=description,
            total_kpis=kpi_count,
            abnormal_kpis=abnormal_kpis
        )

    def _analyze_single_kpi(
        self,
        kpi_name: str,
        values: List[float],
        options: AnalysisOptionsInput
    ) -> Optional[AbnormalKpiDetail]:
        """
        ë‹¨ì¼ KPI ë¶„ì„ ìˆ˜í–‰ (ë²¡í„°í™” ë° ìµœì í™”)

        Args:
            kpi_name: KPI ì´ë¦„
            values: KPI ê°’ë“¤
            options: ë¶„ì„ ì˜µì…˜

        Returns:
            AbnormalKpiDetail or None: ì´ìƒ ê°ì§€ëœ ê²½ìš° ìƒì„¸ ì •ë³´
        """
        try:
            # ë²¡í„°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
            values_array = np.array(values, dtype=np.float64)

            # N-1ê³¼ N ê°’ ì¶”ì¶œ (ë²¡í„°í™”)
            n1_value = values_array[0]   # ì²« ë²ˆì§¸ ê°’ (N-1)
            n_value = values_array[-1]   # ë§ˆì§€ë§‰ ê°’ (N)

            # ë²¡í„°í™”ëœ ë³€í™”ìœ¨ ê³„ì‚°
            if n1_value != 0:
                # ìˆ˜ì¹˜ì  ì•ˆì •ì„±ì„ ìœ„í•œ ê³„ì‚°
                change_rate = abs(np.divide(n_value - n1_value, n1_value))
            else:
                change_rate = 0.0

            # ì„ê³„ì¹˜ ì´ˆê³¼ ì‹œ ì´ìƒìœ¼ë¡œ íŒì •
            if change_rate > options.threshold:
                severity = self._determine_severity(change_rate)

                return AbnormalKpiDetail(
                    kpi_name=kpi_name,
                    n1_value=float(n1_value),  # numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                    n_value=float(n_value),
                    change_rate=float(change_rate),
                    severity=severity
                )

            return None

        except Exception as e:
            self.logger.warning(f"KPI ë¶„ì„ ì‹¤íŒ¨ - {kpi_name}: {e}")
            return None

    def _determine_alarm_level(self, abnormal_score: float) -> str:
        """ì•ŒëŒ ë ˆë²¨ ê²°ì •"""
        if abnormal_score > 0.3:
            return "critical"
        elif abnormal_score > 0.2:
            return "warning"
        elif abnormal_score > 0.1:
            return "caution"
        else:
            return "normal"

    def _determine_severity(self, change_rate: float) -> str:
        """ì‹¬ê°ë„ ê²°ì •"""
        if change_rate > 0.3:
            return "critical"
        elif change_rate > 0.2:
            return "warning"
        else:
            return "caution"

    def _perform_drilldown_analysis(
        self,
        kpi_data: KpiDataInput,
        abnormal_kpis: List[AbnormalKpiDetail],
        options: AnalysisOptionsInput
    ) -> DrilldownAnalysis:
        """
        2ì°¨ ì‹¬ì¸µ ë¶„ì„ ìˆ˜í–‰

        Args:
            kpi_data: ì›ë³¸ KPI ë°ì´í„°
            abnormal_kpis: ì´ìƒ ê°ì§€ëœ KPI ëª©ë¡
            options: ë¶„ì„ ì˜µì…˜

        Returns:
            DrilldownAnalysis: ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼
        """
        self.logger.info("ğŸ”¬ 2ì°¨ ì‹¬ì¸µ ë¶„ì„ ì‹œì‘ - í†µê³„ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰")

        # Top-N ì´ìƒ KPI ì„ íƒ (ìµœëŒ€ 5ê°œ)
        top_abnormal_kpis = abnormal_kpis[:5]
        statistical_analysis = []

        for kpi_detail in top_abnormal_kpis:
            try:
                # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ì—ì„œ ì¶”ì¶œ)
                n1_samples, n_samples = self._generate_samples(
                    kpi_detail.n1_value, kpi_detail.n_value, options.sample_size
                )

                # í†µê³„ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
                mann_whitney_result = self._perform_mann_whitney_test(n1_samples, n_samples)
                ks_result = self._perform_kolmogorov_smirnov_test(n1_samples, n_samples)

                # ì‹ ë¢°ë„ ê³„ì‚°
                confidence = self._calculate_confidence(
                    mann_whitney_result.significant,
                    ks_result.significant
                )

                statistical_analysis.append({
                    "kpiName": kpi_detail.kpi_name,
                    "changeRate": kpi_detail.change_rate,
                    "severity": kpi_detail.severity,
                    "statisticalTests": {
                        "mannWhitney": {
                            "U": mann_whitney_result.statistic,
                            "zScore": mann_whitney_result.effect_size,
                            "pValue": mann_whitney_result.p_value,
                            "significant": mann_whitney_result.significant,
                            "effectSize": mann_whitney_result.effect_size,
                            "interpretation": mann_whitney_result.interpretation
                        },
                        "kolmogorovSmirnov": {
                            "D": ks_result.statistic,
                            "pValue": ks_result.p_value,
                            "significant": ks_result.significant,
                            "distributionDifference": self._determine_distribution_difference(ks_result.statistic),
                            "interpretation": ks_result.interpretation
                        }
                    },
                    "sampleSizes": {
                        "n1": len(n1_samples),
                        "n": len(n_samples)
                    },
                    "confidence": confidence
                })

            except Exception as e:
                self.logger.error(f"í†µê³„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - {kpi_detail.kpiName}: {e}")
                statistical_analysis.append({
                    "kpiName": kpi_detail.kpi_name,
                    "changeRate": kpi_detail.change_rate,
                    "severity": kpi_detail.severity,
                    "statisticalTests": {"error": "í†µê³„ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ ì‹¤íŒ¨"},
                    "confidence": "unknown"
                })

        # ë¶„ì„ ìš”ì•½
        summary = self._create_analysis_summary(statistical_analysis)

        return DrilldownAnalysis(
            statisticalAnalysis=statistical_analysis,
            summary=summary
        )

    def _generate_samples(
        self,
        n1_value: float,
        n_value: float,
        sample_size: int
    ) -> Tuple[List[float], List[float]]:
        """
        ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ë²¡í„°í™” ë° ë©”ëª¨ë¦¬ ìµœì í™”)

        Args:
            n1_value: N-1 ê¸°ê°„ ê¸°ì¤€ê°’
            n_value: N ê¸°ê°„ ê¸°ì¤€ê°’
            sample_size: ìƒì„±í•  ìƒ˜í”Œ ìˆ˜

        Returns:
            Tuple[List[float], List[float]]: (N-1 ìƒ˜í”Œ, N ìƒ˜í”Œ)
        """
        try:
            # ë²¡í„°í™”ëœ ë‚œìˆ˜ ìƒì„±ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
            # í‘œì¤€í¸ì°¨ ê³„ì‚° (ê°’ì˜ 10% ë˜ëŠ” ìµœì†Œê°’ ì‚¬ìš©)
            n1_std = max(abs(n1_value) * 0.1, 1e-6)  # ìµœì†Œ í‘œì¤€í¸ì°¨ ë³´ì¥
            n_std = max(abs(n_value) * 0.1, 1e-6)

            # í•œ ë²ˆì— ëª¨ë“  ìƒ˜í”Œ ìƒì„± (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ)
            n1_samples = np.random.normal(n1_value, n1_std, sample_size)
            n_samples = np.random.normal(n_value, n_std, sample_size)

            # numpy ë°°ì—´ì„ Python ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            return n1_samples.tolist(), n_samples.tolist()

        except Exception as e:
            self.logger.warning(f"ìƒ˜í”Œ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
            # í´ë°±: ê°„ë‹¨í•œ ìƒ˜í”Œ ìƒì„±
            n1_samples = [n1_value] * sample_size
            n_samples = [n_value] * sample_size
            return n1_samples, n_samples

    def _perform_mann_whitney_test(
        self,
        group_a: List[float],
        group_b: List[float]
    ) -> StatisticalTestResult:
        """Mann-Whitney U Test ìˆ˜í–‰ (ìˆ˜ì¹˜ì  ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”)"""
        try:
            # ì…ë ¥ ë°ì´í„° ê²€ì¦
            if not group_a or not group_b:
                raise ValueError("ë¹ˆ ë°ì´í„° ê·¸ë£¹ì…ë‹ˆë‹¤")

            if len(group_a) < 3 or len(group_b) < 3:
                raise ValueError("ê° ê·¸ë£¹ì€ ìµœì†Œ 3ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤")

            # ìˆ˜ì¹˜ì  ì•ˆì •ì„± ê²€ì¦
            for i, val in enumerate(group_a + group_b):
                if not np.isfinite(val):
                    raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ ë°œê²¬: {val} (ì¸ë±ìŠ¤ {i})")

            # ë°ì´í„° ì •ê·œí™” (ê·¹ë‹¨ì ì¸ ê°’ ë°©ì§€)
            all_data = np.array(group_a + group_b)
            data_range = np.ptp(all_data)  # peak-to-peak range

            if data_range == 0:
                return StatisticalTestResult(
                    test_name="Mann-Whitney U",
                    statistic=0.0,
                    p_value=1.0,
                    significant=False,
                    interpretation="ëª¨ë“  ê°’ì´ ë™ì¼í•©ë‹ˆë‹¤"
                )

            # ë„ˆë¬´ í° ë²”ìœ„ì˜ ë°ì´í„°ëŠ” ì •ê·œí™”
            if data_range > 1e10:
                self.logger.warning("ë°ì´í„° ë²”ìœ„ê°€ í½ë‹ˆë‹¤. ì •ê·œí™” ìˆ˜í–‰")
                data_mean = np.mean(all_data)
                data_std = np.std(all_data)
                if data_std > 0:
                    all_data = (all_data - data_mean) / data_std
                    group_a = all_data[:len(group_a)].tolist()
                    group_b = all_data[len(group_a):].tolist()

            # Mann-Whitney U Test ìˆ˜í–‰
            with np.errstate(all='raise'):  # ìˆ˜ì¹˜ì  ì˜ˆì™¸ë¥¼ ì˜ˆì™¸ë¡œ ì²˜ë¦¬
                statistic, p_value = stats.mannwhitneyu(group_a, group_b, alternative='two-sided')

            # p-value ë²”ìœ„ ê²€ì¦ ë° ì¡°ì •
            if not np.isfinite(p_value):
                p_value = 1.0
                self.logger.warning("p-value ê³„ì‚° ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            elif p_value > 1.0:
                p_value = 1.0
            elif p_value < 0.0:
                p_value = 0.0

            # íš¨ê³¼ í¬ê¸° ê³„ì‚° (ìˆ˜ì¹˜ì  ì•ˆì „ì„± ê³ ë ¤)
            n1, n2 = len(group_a), len(group_b)
            try:
                z_score = (statistic - (n1 * n2 / 2)) / np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)
                effect_size = abs(z_score) / np.sqrt(n1 + n2)

                # íš¨ê³¼ í¬ê¸° ë²”ìœ„ ê²€ì¦
                if not np.isfinite(effect_size) or effect_size > 10:
                    effect_size = 1.0
                    self.logger.warning("íš¨ê³¼ í¬ê¸° ê³„ì‚°ì´ ë¹„ì •ìƒì ì…ë‹ˆë‹¤")

            except (ZeroDivisionError, FloatingPointError):
                effect_size = 0.0
                self.logger.warning("íš¨ê³¼ í¬ê¸° ê³„ì‚° ì¤‘ ìˆ˜ì¹˜ì  ì˜¤ë¥˜ ë°œìƒ")

            significant = p_value < 0.05

            interpretation = (
                f"í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ (p={p_value:.4f})"
                if significant
                else f"í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•Šì€ ì°¨ì´ (p={p_value:.4f})"
            )

            return StatisticalTestResult(
                test_name="Mann-Whitney U",
                statistic=statistic,
                p_value=p_value,
                significant=significant,
                interpretation=interpretation,
                effect_size=effect_size
            )

        except (ValueError, RuntimeError, FloatingPointError, np.linalg.LinAlgError) as e:
            self.logger.error(f"Mann-Whitney U Test ìˆ˜ì¹˜ì  ì˜¤ë¥˜: {e}")
            return StatisticalTestResult(
                test_name="Mann-Whitney U",
                statistic=0.0,
                p_value=1.0,
                significant=False,
                interpretation=f"ìˆ˜ì¹˜ì  ê³„ì‚° ì˜¤ë¥˜: {str(e)}"
            )
        except Exception as e:
            self.logger.error(f"Mann-Whitney U Test ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}")
            return StatisticalTestResult(
                test_name="Mann-Whitney U",
                statistic=0.0,
                p_value=1.0,
                significant=False,
                interpretation=f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
            )

    def _perform_kolmogorov_smirnov_test(
        self,
        group_a: List[float],
        group_b: List[float]
    ) -> StatisticalTestResult:
        """Kolmogorov-Smirnov Test ìˆ˜í–‰ (ìˆ˜ì¹˜ì  ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”)"""
        try:
            # ì…ë ¥ ë°ì´í„° ê²€ì¦
            if not group_a or not group_b:
                raise ValueError("ë¹ˆ ë°ì´í„° ê·¸ë£¹ì…ë‹ˆë‹¤")

            if len(group_a) < 3 or len(group_b) < 3:
                raise ValueError("ê° ê·¸ë£¹ì€ ìµœì†Œ 3ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤")

            # ìˆ˜ì¹˜ì  ì•ˆì •ì„± ê²€ì¦
            for i, val in enumerate(group_a + group_b):
                if not np.isfinite(val):
                    raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ ë°œê²¬: {val} (ì¸ë±ìŠ¤ {i})")

            # ë°ì´í„° ì •ê·œí™” (ê·¹ë‹¨ì ì¸ ê°’ ë°©ì§€)
            all_data = np.array(group_a + group_b)
            data_range = np.ptp(all_data)

            if data_range == 0:
                return StatisticalTestResult(
                    test_name="Kolmogorov-Smirnov",
                    statistic=0.0,
                    p_value=1.0,
                    significant=False,
                    interpretation="ëª¨ë“  ê°’ì´ ë™ì¼í•©ë‹ˆë‹¤"
                )

            # Kolmogorov-Smirnov Test ìˆ˜í–‰
            with np.errstate(all='raise'):  # ìˆ˜ì¹˜ì  ì˜ˆì™¸ë¥¼ ì˜ˆì™¸ë¡œ ì²˜ë¦¬
                statistic, p_value = stats.ks_2samp(group_a, group_b)

            # p-value ë²”ìœ„ ê²€ì¦ ë° ì¡°ì •
            if not np.isfinite(p_value):
                p_value = 1.0
                self.logger.warning("KS í…ŒìŠ¤íŠ¸ p-value ê³„ì‚° ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            elif p_value > 1.0:
                p_value = 1.0
            elif p_value < 0.0:
                p_value = 0.0

            # D í†µê³„ëŸ‰ ë²”ìœ„ ê²€ì¦
            if not np.isfinite(statistic) or statistic < 0 or statistic > 1:
                statistic = 0.0
                p_value = 1.0
                self.logger.warning("KS í†µê³„ëŸ‰ì´ ë¹„ì •ìƒì ì…ë‹ˆë‹¤")

            significant = p_value < 0.05

            interpretation = (
                f"ë¶„í¬ì— ìœ ì˜í•œ ì°¨ì´ (D={statistic:.4f}, p={p_value:.4f})"
                if significant
                else f"ë¶„í¬ ì°¨ì´ ë¯¸ë¯¸ (D={statistic:.4f}, p={p_value:.4f})"
            )

            return StatisticalTestResult(
                test_name="Kolmogorov-Smirnov",
                statistic=statistic,
                p_value=p_value,
                significant=significant,
                interpretation=interpretation
            )

        except (ValueError, RuntimeError, FloatingPointError, np.linalg.LinAlgError) as e:
            self.logger.error(f"Kolmogorov-Smirnov Test ìˆ˜ì¹˜ì  ì˜¤ë¥˜: {e}")
            return StatisticalTestResult(
                test_name="Kolmogorov-Smirnov",
                statistic=0.0,
                p_value=1.0,
                significant=False,
                interpretation=f"ìˆ˜ì¹˜ì  ê³„ì‚° ì˜¤ë¥˜: {str(e)}"
            )
        except Exception as e:
            self.logger.error(f"Kolmogorov-Smirnov Test ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}")
            return StatisticalTestResult(
                test_name="Kolmogorov-Smirnov",
                statistic=0.0,
                p_value=1.0,
                significant=False,
                interpretation=f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
            )

    def _determine_distribution_difference(self, d_statistic: float) -> str:
        """ë¶„í¬ ì°¨ì´ ì •ë„ ê²°ì •"""
        if d_statistic > 0.1:
            return "large"
        elif d_statistic > 0.05:
            return "medium"
        else:
            return "small"

    def _calculate_confidence(self, mw_significant: bool, ks_significant: bool) -> str:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        if mw_significant and ks_significant:
            return "high"
        elif mw_significant or ks_significant:
            return "medium"
        else:
            return "low"

    def _create_analysis_summary(self, statistical_analysis: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ë¶„ì„ ìš”ì•½ ìƒì„±"""
        return {
            "totalAnalyzed": len(statistical_analysis),
            "statisticallySignificant": len([
                s for s in statistical_analysis
                if s.get("confidence") in ["high", "medium"]
            ]),
            "highConfidenceFindings": len([
                s for s in statistical_analysis
                if s.get("confidence") == "high"
            ]),
            "distributionChanges": len([
                s for s in statistical_analysis
                if s.get("statisticalTests", {}).get("kolmogorovSmirnov", {}).get("significant")
            ])
        }


    def get_performance_stats(self) -> Dict[str, Any]:
        """
        ì„±ëŠ¥ í†µê³„ ì •ë³´ ë°˜í™˜

        Returns:
            Dict[str, Any]: ì„±ëŠ¥ ê´€ë ¨ í†µê³„ ì •ë³´
        """
        return {
            "service_info": {
                "name": "MahalanobisAnalysisService",
                "version": "1.0.0",
                "numpy_version": np.__version__,
                "scipy_version": stats.__version__ if hasattr(stats, '__version__') else "unknown"
            },
            "capabilities": {
                "vectorized_operations": True,
                "memory_optimization": True,
                "numerical_stability": True,
                "batch_processing": True
            },
            "performance_features": {
                "estimated_memory_monitoring": True,
                "adaptive_batch_size": True,
                "fallback_error_handling": True,
                "statistical_validation": True
            }
        }

    def benchmark_analysis(
        self,
        test_cases: List[Tuple[KpiDataInput, AnalysisOptionsInput]],
        iterations: int = 3
    ) -> Dict[str, Any]:
        """
        ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìˆ˜í–‰

        Args:
            test_cases: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ëª©ë¡
            iterations: ë°˜ë³µ íšŸìˆ˜

        Returns:
            Dict[str, Any]: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
        """
        import time
        results = []

        for i, (kpi_data, options) in enumerate(test_cases):
            case_results = []

            for j in range(iterations):
                start_time = time.perf_counter()

                try:
                    result = self.calculate_mahalanobis_distance(kpi_data, options)
                    processing_time = result.processing_time

                    case_results.append({
                        "iteration": j + 1,
                        "success": True,
                        "processing_time": processing_time,
                        "kpi_count": result.data.total_kpis,
                        "abnormal_count": len(result.data.abnormal_kpis)
                    })

                except Exception as e:
                    case_results.append({
                        "iteration": j + 1,
                        "success": False,
                        "error": str(e),
                        "processing_time": 0.0
                    })

            # ì¼€ì´ìŠ¤ë³„ í‰ê·  ê³„ì‚°
            successful_runs = [r for r in case_results if r["success"]]
            avg_time = np.mean([r["processing_time"] for r in successful_runs]) if successful_runs else 0

            results.append({
                "test_case": i + 1,
                "iterations": iterations,
                "success_rate": len(successful_runs) / iterations,
                "average_time": avg_time,
                "min_time": min([r["processing_time"] for r in successful_runs]) if successful_runs else 0,
                "max_time": max([r["processing_time"] for r in successful_runs]) if successful_runs else 0,
                "details": case_results
            })

        return {
            "benchmark_summary": {
                "total_test_cases": len(test_cases),
                "total_iterations": len(test_cases) * iterations,
                "overall_success_rate": np.mean([r["success_rate"] for r in results])
            },
            "results": results,
            "timestamp": datetime.utcnow().isoformat()
        }


    def perform_mann_whitney_test(
        self,
        group_a: List[float],
        group_b: List[float],
        significance_level: float = 0.05
    ) -> StatisticalTestResult:
        """
        ë…ë¦½ì ì¸ Mann-Whitney U Test ìˆ˜í–‰ (APIìš©)

        Args:
            group_a: ì²« ë²ˆì§¸ ê·¸ë£¹ì˜ ë°ì´í„°
            group_b: ë‘ ë²ˆì§¸ ê·¸ë£¹ì˜ ë°ì´í„°
            significance_level: ìœ ì˜ ìˆ˜ì¤€

        Returns:
            StatisticalTestResult: í…ŒìŠ¤íŠ¸ ê²°ê³¼
        """
        return self._perform_mann_whitney_test(group_a, group_b)

    def perform_kolmogorov_smirnov_test(
        self,
        group_a: List[float],
        group_b: List[float],
        significance_level: float = 0.05
    ) -> StatisticalTestResult:
        """
        ë…ë¦½ì ì¸ Kolmogorov-Smirnov Test ìˆ˜í–‰ (APIìš©)

        Args:
            group_a: ì²« ë²ˆì§¸ ê·¸ë£¹ì˜ ë°ì´í„°
            group_b: ë‘ ë²ˆì§¸ ê·¸ë£¹ì˜ ë°ì´í„°
            significance_level: ìœ ì˜ ìˆ˜ì¤€

        Returns:
            StatisticalTestResult: í…ŒìŠ¤íŠ¸ ê²°ê³¼
        """
        return self._perform_kolmogorov_smirnov_test(group_a, group_b)


# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì‹±ê¸€í†¤ íŒ¨í„´)
mahalanobis_service = MahalanobisAnalysisService()
