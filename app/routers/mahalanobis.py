"""
ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ë¶„ì„ API ë¼ìš°í„°

ì´ ëª¨ë“ˆì€ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ë¶„ì„ì„ ìœ„í•œ FastAPI ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import logging
import hashlib
import json
from datetime import datetime
from typing import Dict, Any
from fastapi import APIRouter, HTTPException, status, Depends
from fastapi.responses import JSONResponse

from ..models.mahalanobis import (
    KpiDataInput,
    AnalysisOptionsInput,
    MahalanobisAnalysisResult,
    StatisticalTestInput,
    StatisticalTestResponse
)
from ..services.mahalanobis_service import mahalanobis_service
from ..utils.cache_manager import get_cache_manager
from ..utils.prometheus_metrics import record_analysis

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ìºì‹œ ë²„ì „ ê´€ë¦¬ (ìºì‹œ ë¬´íš¨í™”ë¥¼ ìœ„í•œ ë²„ì „)
CACHE_VERSION = "1.0"

# ìºì‹œ í‚¤ ìƒì„± í•¨ìˆ˜
def generate_cache_key(kpi_data: KpiDataInput, options: AnalysisOptionsInput, version: str = None) -> str:
    """
    ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ì„ ìœ„í•œ ìºì‹œ í‚¤ ìƒì„±

    Args:
        kpi_data: KPI ë°ì´í„° ì…ë ¥
        options: ë¶„ì„ ì˜µì…˜
        version: ìºì‹œ ë²„ì „ (ì˜µì…˜, ê¸°ë³¸ê°’: CACHE_VERSION)

    Returns:
        str: ìºì‹œ í‚¤
    """
    if version is None:
        version = CACHE_VERSION

    # ìºì‹œ í‚¤ ë°ì´í„° êµ¬ì„±
    cache_data = {
        "kpi_data": kpi_data.kpi_data,
        "timestamps": kpi_data.timestamps,
        "period_labels": kpi_data.period_labels,
        "threshold": options.threshold,
        "sample_size": options.sample_size,
        "significance_level": options.significance_level,
        "version": version  # ìºì‹œ ë¬´íš¨í™”ë¥¼ ìœ„í•œ ë²„ì „
    }

    # ë°ì´í„°ë¥¼ ì •ë ¬í•˜ì—¬ ì¼ê´€ëœ í•´ì‹œ ìƒì„±
    cache_string = json.dumps(cache_data, sort_keys=True, default=str)

    # SHA-256 í•´ì‹œ ìƒì„±
    cache_key = hashlib.sha256(cache_string.encode()).hexdigest()

    return f"mahalanobis:{version}:{cache_key}"

# ìºì‹œ TTL ì„¤ì • (30ë¶„)
MAHALANOBIS_CACHE_TTL = 1800

# ë¼ìš°í„° ìƒì„±
router = APIRouter(
    prefix="/api/analysis",
    tags=["analysis"],
    responses={
        500: {"description": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜"},
        400: {"description": "ì˜ëª»ëœ ìš”ì²­"},
        422: {"description": "ë°ì´í„° ê²€ì¦ ì˜¤ë¥˜"}
    }
)


@router.post(
    "/mahalanobis",
    response_model=MahalanobisAnalysisResult,
    summary="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ë¶„ì„ ìˆ˜í–‰",
    description="""
    KPI ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ì´ìƒ ê°ì§€ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    **ë¶„ì„ ê³¼ì •:**
    1. **1ì°¨ ìŠ¤í¬ë¦¬ë‹**: ê° KPIì˜ ë³€í™”ìœ¨ì„ ê³„ì‚°í•˜ì—¬ ì„ê³„ì¹˜ ê¸°ë°˜ ì´ìƒ ê°ì§€
    2. **ì´ìƒ KPI ì„ ë³„**: ë³€í™”ìœ¨ì´ í° KPIë“¤ì„ ì¶”ì¶œ
    3. **2ì°¨ ì‹¬ì¸µ ë¶„ì„**: ì„ ë³„ëœ KPIë“¤ì— ëŒ€í•´ í†µê³„ì  ê²€ì • ìˆ˜í–‰
    4. **ì¢…í•© íŒì •**: ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ì•ŒëŒ ë ˆë²¨ ê²°ì •

    **í†µê³„ í…ŒìŠ¤íŠ¸:**
    - Mann-Whitney U Test: ë‘ ê·¸ë£¹ì˜ ì¤‘ì•™ê°’ ì°¨ì´ ê²€ì •
    - Kolmogorov-Smirnov Test: ë‘ ê·¸ë£¹ì˜ ë¶„í¬ ì°¨ì´ ê²€ì •

    **ì•ŒëŒ ë ˆë²¨:**
    - `normal`: ì •ìƒ ë²”ìœ„
    - `caution`: ì£¼ì˜ í•„ìš” (ì•½í•œ ì´ìƒ ê°ì§€)
    - `warning`: ê²½ê³  (ì¤‘ê°„ ì •ë„ ì´ìƒ ê°ì§€)
    - `critical`: ì‹¬ê° (ê°•í•œ ì´ìƒ ê°ì§€)
    """,
    responses={
        200: {
            "description": "ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ì„±ê³µ",
            "content": {
                "application/json": {
                    "example": {
                        "data": {
                            "totalKpis": 3,
                            "abnormalKpis": [
                                {
                                    "kpiName": "RACH Success Rate",
                                    "n1Value": 98.5,
                                    "nValue": 85.2,
                                    "changeRate": 0.135,
                                    "severity": "caution"
                                }
                            ],
                            "abnormalScore": 0.333,
                            "alarmLevel": "caution",
                            "analysis": {
                                "screening": {
                                    "status": "caution",
                                    "score": 0.333,
                                    "threshold": 0.1,
                                    "description": "ë¹„ì •ìƒ íŒ¨í„´ ê°ì§€ë¨"
                                },
                                "drilldown": {
                                    "statisticalAnalysis": [
                                        {
                                            "kpiName": "RACH Success Rate",
                                            "changeRate": 0.135,
                                            "severity": "caution",
                                            "statisticalTests": {
                                                "mannWhitney": {
                                                    "U": 25.0,
                                                    "pValue": 0.0079,
                                                    "significant": True,
                                                    "interpretation": "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ (p=0.0079)"
                                                },
                                                "kolmogorovSmirnov": {
                                                    "D": 1.0,
                                                    "pValue": 0.0079,
                                                    "significant": True,
                                                    "interpretation": "ë¶„í¬ì— ìœ ì˜í•œ ì°¨ì´ (D=1.0000, p=0.0079)"
                                                }
                                            }
                                        }
                                    ],
                                    "summary": {
                                        "totalAnalyzed": 1,
                                        "statisticallySignificant": 1,
                                        "highConfidenceFindings": 1
                                    }
                                }
                            }
                        },
                        "processingTime": 0.0035
                    }
                }
            }
        },
        422: {
            "description": "ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "KPI ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
                    }
                }
            }
        }
    }
)
async def perform_mahalanobis_analysis(
    kpi_data: KpiDataInput,
    options: AnalysisOptionsInput,
    cache_manager = Depends(get_cache_manager)
) -> MahalanobisAnalysisResult:
    """
    ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸ (ìºì‹± ì§€ì›)

    Args:
        kpi_data: KPI ë°ì´í„° ì…ë ¥
        options: ë¶„ì„ ì˜µì…˜
        cache_manager: ìºì‹œ ê´€ë¦¬ì

    Returns:
        MahalanobisAnalysisResult: ë¶„ì„ ê²°ê³¼

    Raises:
        HTTPException: ìš”ì²­ ì˜¤ë¥˜ ë˜ëŠ” ì„œë²„ ì˜¤ë¥˜
    """
    start_time = datetime.utcnow()
    cache_hit = False

    try:
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = generate_cache_key(kpi_data, options)
        logger.info(f"ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ë¶„ì„ ìš”ì²­ ì‹œì‘ - ìºì‹œ í‚¤: {cache_key[:16]}...")

        # ìºì‹œ ì¡°íšŒ (í´ë°± ë©”ì»¤ë‹ˆì¦˜ ì ìš©)
        cache_available = True
        cached_result = None

        try:
            cached_result = await cache_manager.get(cache_key)
        except Exception as cache_error:
            logger.warning(f"ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {cache_error}, ìºì‹œ ì—†ì´ ë¶„ì„ ì§„í–‰")
            cache_available = False

        if cached_result is not None and cache_available:
            cache_hit = True
            logger.info("âš¡ ìºì‹œ íˆíŠ¸: ì €ì¥ëœ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ê²°ê³¼ ë°˜í™˜")

            # ìºì‹œëœ ë°ì´í„°ë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
            if isinstance(cached_result, dict):
                result = MahalanobisAnalysisResult(**cached_result)
            else:
                # JSON ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
                import json
                try:
                    cached_data = json.loads(cached_result)
                    result = MahalanobisAnalysisResult(**cached_data)
                except (json.JSONDecodeError, ValueError) as e:
                    logger.warning(f"ìºì‹œ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}, ì¬ê³„ì‚° ìˆ˜í–‰")
                    cached_result = None
                    cache_hit = False

        if not cache_hit:
            logger.info(f"ğŸ“Š ìºì‹œ ë¯¸ìŠ¤: ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ê³„ì‚° ì‹œì‘ - KPI ìˆ˜: {len(kpi_data.kpi_data)}, ì„ê³„ê°’: {options.threshold}")

            # ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ìˆ˜í–‰
            result = mahalanobis_service.calculate_mahalanobis_distance(kpi_data, options)

            # ìºì‹œì— ì €ì¥ (ìºì‹œê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ)
            if cache_available:
                try:
                    result_dict = result.model_dump()
                    await cache_manager.set(cache_key, result_dict, ttl=MAHALANOBIS_CACHE_TTL)
                    logger.info(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ìºì‹œ ì €ì¥ ì™„ë£Œ (TTL: {MAHALANOBIS_CACHE_TTL}ì´ˆ)")
                except Exception as cache_error:
                    logger.warning(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨ (í´ë°± ëª¨ë“œë¡œ ê³„ì† ì§„í–‰): {cache_error}")
            else:
                logger.info("ğŸ’¾ ìºì‹œ ì €ì¥ ìƒëµ (ìºì‹œ ì‹œìŠ¤í…œ unavailable)")

        processing_time = (datetime.utcnow() - start_time).total_seconds()

        # ì²˜ë¦¬ ì‹œê°„ ì •ë³´ ì¶”ê°€
        result_dict = result.model_dump()
        result_dict['apiProcessingTime'] = processing_time
        result_dict['cacheHit'] = cache_hit
        result_dict['cacheAvailable'] = cache_available

        # ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        try:
            if cache_available:
                cache_stats = await cache_manager.get_stats()
                result_dict['cacheStats'] = {
                    'hitRate': cache_stats.get('hit_rate', 0),
                    'size': cache_stats.get('size', 0),
                    'type': cache_stats.get('type', 'unknown')
                }
        except Exception as metrics_error:
            logger.debug(f"ìºì‹œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {metrics_error}")

        # Prometheus ë©”íŠ¸ë¦­ ê¸°ë¡
        try:
            kpi_count = len(kpi_data.kpi_data) if kpi_data.kpi_data else 0
            abnormal_kpi_count = len(result_dict.get('data', {}).get('abnormalKpis', []))
            analysis_status = "success" if result.success else "failed"

            record_analysis(
                status=analysis_status,
                duration=processing_time,
                kpi_count=kpi_count,
                abnormal_kpi_count=abnormal_kpi_count,
                cache_hit=cache_hit
            )
        except Exception as metrics_error:
            logger.debug(f"ë¶„ì„ ë©”íŠ¸ë¦­ ê¸°ë¡ ì‹¤íŒ¨: {metrics_error}")

        logger.info(f"ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ë¶„ì„ ì™„ë£Œ - ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ, ìºì‹œ íˆíŠ¸: {cache_hit}, ìºì‹œ ì‚¬ìš© ê°€ëŠ¥: {cache_available}")

        return MahalanobisAnalysisResult(**result_dict)

    except ValueError as e:
        logger.warning(f"ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ê²€ì¦ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail=f"ë°ì´í„° ê²€ì¦ ì˜¤ë¥˜: {str(e)}"
        )

    except RuntimeError as e:
        logger.error(f"ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ëŸ°íƒ€ì„ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ë¶„ì„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
        )

    except Exception as e:
        logger.error(f"ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ì„œë²„ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {str(e)}"
        )


@router.post(
    "/mahalanobis/quick",
    response_model=MahalanobisAnalysisResult,
    summary="ë¹ ë¥¸ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ (ê¸°ë³¸ ì˜µì…˜)",
    description="""
    ê¸°ë³¸ ë¶„ì„ ì˜µì…˜ìœ¼ë¡œ ë¹ ë¥´ê²Œ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    **ê¸°ë³¸ ì˜µì…˜:**
    - ì„ê³„ê°’: 0.1 (10%)
    - ìƒ˜í”Œ í¬ê¸°: 20
    - ìœ ì˜ ìˆ˜ì¤€: 0.05

    **ì‚¬ìš© ì‚¬ë¡€:**
    - ë¹ ë¥¸ ì´ìƒ ê°ì§€
    - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
    - ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¶©ë¶„í•œ ê²½ìš°
    """,
    responses={
        200: {
            "description": "ë¹ ë¥¸ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ì„±ê³µ"
        }
    }
)
async def perform_quick_mahalanobis_analysis(
    kpi_data: KpiDataInput,
    cache_manager = Depends(get_cache_manager)
) -> MahalanobisAnalysisResult:
    """
    ë¹ ë¥¸ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸ (ìºì‹± ì§€ì›)

    ê¸°ë³¸ ì˜µì…˜ìœ¼ë¡œ ë¹ ë¥´ê²Œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        kpi_data: KPI ë°ì´í„° ì…ë ¥
        cache_manager: ìºì‹œ ê´€ë¦¬ì

    Returns:
        MahalanobisAnalysisResult: ë¶„ì„ ê²°ê³¼
    """
    # ê¸°ë³¸ ì˜µì…˜ ì„¤ì •
    default_options = AnalysisOptionsInput(
        threshold=0.1,
        sample_size=20,
        significance_level=0.05
    )

    # ì¼ë°˜ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ (ìºì‹œ ë§¤ë‹ˆì € ì „ë‹¬)
    return await perform_mahalanobis_analysis(kpi_data, default_options, cache_manager)


@router.get(
    "/mahalanobis/info",
    summary="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤ ì •ë³´",
    description="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤ì˜ ë²„ì „ê³¼ ì§€ì› ê¸°ëŠ¥ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any]
)
async def get_mahalanobis_info() -> Dict[str, Any]:
    """
    ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤ ì •ë³´ ì—”ë“œí¬ì¸íŠ¸

    Returns:
        Dict[str, Any]: ì„œë¹„ìŠ¤ ì •ë³´
    """
    try:
        service_info = mahalanobis_service.get_performance_stats()

        return {
            "service": service_info,
            "endpoints": [
                {
                    "path": "/api/analysis/mahalanobis",
                    "method": "POST",
                    "description": "ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ë¶„ì„ ìˆ˜í–‰"
                },
                {
                    "path": "/api/analysis/mahalanobis/quick",
                    "method": "POST",
                    "description": "ë¹ ë¥¸ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ (ê¸°ë³¸ ì˜µì…˜)"
                }
            ],
            "supportedAlgorithms": [
                "Mahalanobis Distance",
                "Mann-Whitney U Test",
                "Kolmogorov-Smirnov Test"
            ],
            "analysisTypes": [
                "1ì°¨ ìŠ¤í¬ë¦¬ë‹ (ë³€í™”ìœ¨ ê¸°ë°˜)",
                "2ì°¨ ì‹¬ì¸µ ë¶„ì„ (í†µê³„ ê²€ì •)",
                "ì¢…í•© ì´ìƒ ì ìˆ˜ ê³„ì‚°",
                "ì•ŒëŒ ë ˆë²¨ íŒì •"
            ],
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }

    except Exception as e:
        logger.error(f"ì„œë¹„ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì„œë¹„ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨"
        )


@router.get(
    "/mahalanobis/health",
    summary="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ API ìƒíƒœ í™•ì¸",
    description="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ APIì˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any]
)
async def mahalanobis_health_check(
    cache_manager = Depends(get_cache_manager)
) -> Dict[str, Any]:
    """
    ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ API ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸

    Args:
        cache_manager: ìºì‹œ ê´€ë¦¬ì

    Returns:
        Dict[str, Any]: ìƒíƒœ ì •ë³´
    """
    try:
        start_time = datetime.utcnow()

        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ìœ¼ë¡œ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        test_kpi_data = KpiDataInput(
            kpiData={
                'test': [100.0, 101.0]
            }
        )
        test_options = AnalysisOptionsInput()

        result = mahalanobis_service.calculate_mahalanobis_distance(test_kpi_data, test_options)

        # ìºì‹œ ìƒíƒœ í™•ì¸
        cache_stats = await cache_manager.get_stats()

        processing_time = (datetime.utcnow() - start_time).total_seconds()

        return {
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "service": "MahalanobisAnalysisService",
            "version": "1.0.0",
            "test_status": "passed" if result.success else "failed",
            "response_time": f"{processing_time:.4f}s",
            "cache": {
                "status": "available",
                "type": cache_stats.get("type", "unknown"),
                "size": cache_stats.get("size", 0),
                "hit_rate": cache_stats.get("hit_rate", 0),
                "mahalanobis_cache_ttl": MAHALANOBIS_CACHE_TTL
            }
        }

    except Exception as e:
        logger.error(f"ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ API ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        return {
            "status": "unhealthy",
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "service": "MahalanobisAnalysisService",
            "error": str(e),
            "cache": {
                "status": "unavailable"
            }
        }


@router.get(
    "/cache/stats",
    summary="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ìºì‹œ í†µê³„ ì¡°íšŒ",
    description="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ìºì‹œì˜ í†µê³„ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any]
)
async def get_cache_stats(
    cache_manager = Depends(get_cache_manager)
) -> Dict[str, Any]:
    """
    ìºì‹œ í†µê³„ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸

    Args:
        cache_manager: ìºì‹œ ê´€ë¦¬ì

    Returns:
        Dict[str, Any]: ìºì‹œ í†µê³„ ì •ë³´
    """
    try:
        stats = await cache_manager.get_stats()

        # ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê´€ë ¨ ìºì‹œ í•­ëª© ìˆ˜ ê³„ì‚°
        mahalanobis_keys = 0
        total_keys = 0
        mahalanobis_memory_usage = 0

        try:
            all_keys = await cache_manager.get_all_keys()
            total_keys = len(all_keys)
            mahalanobis_keys = len([key for key in all_keys if key.startswith("mahalanobis:")])

            # ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ìºì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
            for key in all_keys:
                if key.startswith("mahalanobis:"):
                    try:
                        value = await cache_manager.get(key)
                        if value:
                            # ëŒ€ëµì ì¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚° (í‚¤ + ê°’)
                            key_size = len(key.encode('utf-8'))
                            value_size = len(str(value).encode('utf-8')) if isinstance(value, (dict, list)) else len(str(value).encode('utf-8'))
                            mahalanobis_memory_usage += key_size + value_size
                    except Exception as e:
                        logger.debug(f"ìºì‹œ í•­ëª© ë©”ëª¨ë¦¬ ê³„ì‚° ì‹¤íŒ¨: {key} - {e}")

        except Exception as e:
            logger.warning(f"ìºì‹œ í‚¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
        hit_count = stats.get("hit_count", 0)
        miss_count = stats.get("miss_count", 0)
        total_requests = hit_count + miss_count
        calculated_hit_rate = (hit_count / total_requests * 100) if total_requests > 0 else 0

        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì¶”ì • (ìºì‹œ íˆíŠ¸ vs ë¯¸ìŠ¤)
        avg_hit_time = 0.001  # 1ms (ìºì‹œ íˆíŠ¸)
        avg_miss_time = 0.100  # 100ms (ìºì‹œ ë¯¸ìŠ¤ + ê³„ì‚°)
        avg_response_time = (hit_count * avg_hit_time + miss_count * avg_miss_time) / total_requests if total_requests > 0 else 0

        return {
            "cache_type": stats.get("type", "unknown"),
            "size": stats.get("size", 0),
            "max_size": stats.get("max_size", 0),
            "hit_rate": stats.get("hit_rate", calculated_hit_rate),
            "hit_count": hit_count,
            "miss_count": miss_count,
            "total_requests": total_requests,
            "avg_response_time": round(avg_response_time, 4),
            "mahalanobis_entries": mahalanobis_keys,
            "total_entries": total_keys,
            "mahalanobis_memory_usage": mahalanobis_memory_usage,
            "mahalanobis_cache_ttl": MAHALANOBIS_CACHE_TTL,
            "cache_version": CACHE_VERSION,
            "performance_metrics": {
                "cache_efficiency": calculated_hit_rate,
                "time_saved": round(miss_count * (avg_miss_time - avg_hit_time), 4),
                "mahalanobis_ratio": (mahalanobis_keys / total_keys * 100) if total_keys > 0 else 0
            },
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }

    except Exception as e:
        logger.error(f"ìºì‹œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ìºì‹œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        )


@router.post(
    "/cache/clear",
    summary="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ìºì‹œ ì •ë¦¬",
    description="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any]
)
async def clear_cache(
    pattern: str = None,
    cache_manager = Depends(get_cache_manager)
) -> Dict[str, Any]:
    """
    ìºì‹œ ì •ë¦¬ ì—”ë“œí¬ì¸íŠ¸

    Args:
        pattern: ì •ë¦¬í•  íŒ¨í„´ (ì˜µì…˜, ê¸°ë³¸ê°’: "mahalanobis:")
        cache_manager: ìºì‹œ ê´€ë¦¬ì

    Returns:
        Dict[str, Any]: ì •ë¦¬ ê²°ê³¼
    """
    try:
        if pattern is None:
            pattern = "mahalanobis:"

        logger.info(f"ìºì‹œ ì •ë¦¬ ìš”ì²­: íŒ¨í„´ '{pattern}'")

        # ìºì‹œ ì •ë¦¬ ìˆ˜í–‰
        cleared_count = await cache_manager.clear_pattern(pattern)

        logger.info(f"ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {cleared_count}ê°œ í•­ëª© ì œê±°")

        return {
            "success": True,
            "cleared_count": cleared_count,
            "pattern": pattern,
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }

    except Exception as e:
        logger.error(f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}"
        )


@router.post(
    "/cache/invalidate",
    summary="íŠ¹ì • ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ìºì‹œ ë¬´íš¨í™”",
    description="íŠ¹ì • ìºì‹œ í‚¤ë¥¼ ë¬´íš¨í™”í•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any]
)
async def invalidate_cache(
    cache_key: str,
    cache_manager = Depends(get_cache_manager)
) -> Dict[str, Any]:
    """
    ìºì‹œ ë¬´íš¨í™” ì—”ë“œí¬ì¸íŠ¸

    Args:
        cache_key: ë¬´íš¨í™”í•  ìºì‹œ í‚¤
        cache_manager: ìºì‹œ ê´€ë¦¬ì

    Returns:
        Dict[str, Any]: ë¬´íš¨í™” ê²°ê³¼
    """
    try:
        logger.info(f"ìºì‹œ ë¬´íš¨í™” ìš”ì²­: {cache_key}")

        # ìºì‹œ í‚¤ ì¡´ì¬ í™•ì¸
        exists = await cache_manager.exists(cache_key)

        if exists:
            # ìºì‹œ ì‚­ì œ
            await cache_manager.delete(cache_key)
            logger.info(f"ìºì‹œ ë¬´íš¨í™” ì™„ë£Œ: {cache_key}")

            return {
                "success": True,
                "cache_key": cache_key,
                "invalidated": True,
                "timestamp": datetime.utcnow().isoformat() + "Z"
            }
        else:
            logger.info(f"ìºì‹œ í‚¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {cache_key}")

            return {
                "success": True,
                "cache_key": cache_key,
                "invalidated": False,
                "message": "ìºì‹œ í‚¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤",
                "timestamp": datetime.utcnow().isoformat() + "Z"
            }

    except Exception as e:
        logger.error(f"ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨: {str(e)}"
        )


@router.post(
    "/cache/invalidate-version",
    summary="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ìºì‹œ ë²„ì „ ë¬´íš¨í™”",
    description="íŠ¹ì • ë²„ì „ì˜ ëª¨ë“  ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ìºì‹œë¥¼ ë¬´íš¨í™”í•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any]
)
async def invalidate_cache_version(
    version: str = None,
    cache_manager = Depends(get_cache_manager)
) -> Dict[str, Any]:
    """
    ìºì‹œ ë²„ì „ ë¬´íš¨í™” ì—”ë“œí¬ì¸íŠ¸

    Args:
        version: ë¬´íš¨í™”í•  ë²„ì „ (ì˜µì…˜, ê¸°ë³¸ê°’: í˜„ì¬ ë²„ì „)
        cache_manager: ìºì‹œ ê´€ë¦¬ì

    Returns:
        Dict[str, Any]: ë¬´íš¨í™” ê²°ê³¼
    """
    try:
        if version is None:
            version = CACHE_VERSION

        pattern = f"mahalanobis:{version}:*"
        logger.info(f"ìºì‹œ ë²„ì „ ë¬´íš¨í™” ìš”ì²­: ë²„ì „ {version}")

        # í•´ë‹¹ ë²„ì „ì˜ ëª¨ë“  ìºì‹œ ì •ë¦¬
        cleared_count = await cache_manager.clear_pattern(pattern)

        logger.info(f"ìºì‹œ ë²„ì „ ë¬´íš¨í™” ì™„ë£Œ: ë²„ì „ {version}, {cleared_count}ê°œ í•­ëª© ì œê±°")

        return {
            "success": True,
            "version": version,
            "cleared_count": cleared_count,
            "pattern": pattern,
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }

    except Exception as e:
        logger.error(f"ìºì‹œ ë²„ì „ ë¬´íš¨í™” ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ìºì‹œ ë²„ì „ ë¬´íš¨í™” ì‹¤íŒ¨: {str(e)}"
        )


@router.post(
    "/cache/update-version",
    summary="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ìºì‹œ ë²„ì „ ì—…ë°ì´íŠ¸",
    description="ìºì‹œ ë²„ì „ì„ ì—…ë°ì´íŠ¸í•˜ì—¬ ì´ì „ ë²„ì „ ìºì‹œë¥¼ ë¬´íš¨í™”í•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any]
)
async def update_cache_version(
    new_version: str,
    cache_manager = Depends(get_cache_manager)
) -> Dict[str, Any]:
    """
    ìºì‹œ ë²„ì „ ì—…ë°ì´íŠ¸ ì—”ë“œí¬ì¸íŠ¸

    Args:
        new_version: ìƒˆë¡œìš´ ë²„ì „
        cache_manager: ìºì‹œ ê´€ë¦¬ì

    Returns:
        Dict[str, Any]: ì—…ë°ì´íŠ¸ ê²°ê³¼
    """
    try:
        global CACHE_VERSION
        old_version = CACHE_VERSION

        logger.info(f"ìºì‹œ ë²„ì „ ì—…ë°ì´íŠ¸ ìš”ì²­: {old_version} â†’ {new_version}")

        # ì´ì „ ë²„ì „ ìºì‹œ ì •ë¦¬
        old_pattern = f"mahalanobis:{old_version}:*"
        cleared_count = await cache_manager.clear_pattern(old_pattern)

        # ë²„ì „ ì—…ë°ì´íŠ¸
        CACHE_VERSION = new_version

        logger.info(f"ìºì‹œ ë²„ì „ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {old_version} â†’ {new_version}, {cleared_count}ê°œ ì´ì „ ë²„ì „ ìºì‹œ ì œê±°")

        return {
            "success": True,
            "old_version": old_version,
            "new_version": new_version,
            "cleared_count": cleared_count,
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }

    except Exception as e:
        logger.error(f"ìºì‹œ ë²„ì „ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ìºì‹œ ë²„ì „ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}"
        )


@router.get(
    "/cache/version",
    summary="í˜„ì¬ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ìºì‹œ ë²„ì „ ì¡°íšŒ",
    description="í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ìºì‹œ ë²„ì „ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
    response_model=Dict[str, Any]
)
async def get_cache_version() -> Dict[str, Any]:
    """
    ìºì‹œ ë²„ì „ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸

    Returns:
        Dict[str, Any]: ë²„ì „ ì •ë³´
    """
    return {
        "version": CACHE_VERSION,
        "ttl": MAHALANOBIS_CACHE_TTL,
        "timestamp": datetime.utcnow().isoformat() + "Z"
    }
