"""
LLM ë¶„ì„ API ë¼ìš°í„° V2

Frontend Dashboardì—ì„œ MCP ë¶„ì„ì„ íŠ¸ë¦¬ê±°í•˜ê³  ê²°ê³¼ë¥¼ V2 í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
MCPì˜ AnalysisServiceë¥¼ ì§ì ‘ importí•˜ì—¬ Python ëª¨ë“ˆë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

import logging
import uuid
import sys
import os
from datetime import datetime
from typing import Dict, Any
from fastapi import APIRouter, HTTPException, BackgroundTasks, Body, status

from ..db import get_database

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# MCP ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
MCP_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../3gpp_analysis_mcp"))
if MCP_PATH not in sys.path:
    sys.path.insert(0, MCP_PATH)
    logger.info(f"MCP ê²½ë¡œ ì¶”ê°€: {MCP_PATH}")

# MCP ëª¨ë“ˆ import
try:
    from analysis_llm.services import AnalysisService, AnalysisServiceError
    from analysis_llm.repositories import PostgreSQLRepository
    from analysis_llm.utils import TimeRangeParser, DataProcessor
    
    MCP_AVAILABLE = True
    logger.info("MCP ëª¨ë“ˆ import ì„±ê³µ")
except ImportError as e:
    MCP_AVAILABLE = False
    logger.error(f"MCP ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    AnalysisService = None
    AnalysisServiceError = None


# ë¼ìš°í„° ìƒì„±
router = APIRouter()


@router.post(
    "/api/analysis/trigger-llm-analysis-v2",
    status_code=status.HTTP_202_ACCEPTED,
    summary="LLM ë¶„ì„ íŠ¸ë¦¬ê±° (V2 - MCP ì§ì ‘ í˜¸ì¶œ)",
    description="Dashboardì—ì„œ LLM ë¶„ì„ì„ íŠ¸ë¦¬ê±°í•˜ê³  MCPë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ results-v2ì— ì €ì¥í•©ë‹ˆë‹¤."
)
async def trigger_llm_analysis_v2(
    request_data: Dict[str, Any] = Body(...),
    background_tasks: BackgroundTasks = None
):
    """
    LLM ë¶„ì„ì„ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤ (V2).
    
    Request body:
    {
        "n_minus_1": "2025-01-19_00:00~2025-01-19_23:59",  // Time1 (N-1 ê¸°ê°„)
        "n": "2025-01-20_00:00~2025-01-20_23:59",           // Time2 (N ê¸°ê°„)
        "ne_id": "nvgnb#10000",                              // NE ì„ íƒ (ì„ íƒ)
        "cell_id": "2010",                                   // Cell ID ì„ íƒ (ì„ íƒ)
        "db_config": {                                       // DB ì„¤ì •
            "host": "...",
            "port": 5432,
            "user": "postgres",
            "password": "...",
            "dbname": "peg_db",
            "table": "summary"
        }
    }
    
    Returns:
        ë¶„ì„ IDì™€ ìƒíƒœ ì •ë³´
    """
    if not MCP_AVAILABLE:
        raise HTTPException(
            status_code=500,
            detail="MCP ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
        )
    
    try:
        analysis_id = str(uuid.uuid4())
        
        logger.info(f"ğŸš€ LLM ë¶„ì„ V2 ìš”ì²­ ì‹œì‘: {analysis_id}")
        logger.info(f"ğŸ“Š ìš”ì²­ ë°ì´í„°: {request_data.keys()}")
        
        # ì‚¬ìš©ì Preferenceì—ì„œ DB ì„¤ì • ë³‘í•©
        user_id = request_data.get("user_id", "default")
        db = get_database()
        pref = await db.user_preferences.find_one({"user_id": user_id})
        pref_db = (pref or {}).get("database_settings", {})
        
        request_db_config = request_data.get("db_config") or {}
        effective_db_config = {
            "host": request_db_config.get("host", pref_db.get("host")),
            "port": request_db_config.get("port", pref_db.get("port", 5432)),
            "user": request_db_config.get("user", pref_db.get("user", "postgres")),
            "password": request_db_config.get("password", pref_db.get("password")),
            "dbname": request_db_config.get("dbname", pref_db.get("dbname", "postgres")),
            "table": request_data.get("table") or request_db_config.get("table") or pref_db.get("table", "summary"),
        }
        
        logger.info(f"ğŸ”Œ DB ì„¤ì •: host={effective_db_config.get('host')}, "
                   f"dbname={effective_db_config.get('dbname')}, "
                   f"table={effective_db_config.get('table')}")
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ MCP ë¶„ì„ ì‹¤í–‰
        if background_tasks:
            background_tasks.add_task(
                execute_mcp_analysis_and_save_v2,
                analysis_id,
                effective_db_config,
                request_data
            )
        else:
            # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ê°€ ì—†ìœ¼ë©´ ë™ê¸° ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
            await execute_mcp_analysis_and_save_v2(
                analysis_id,
                effective_db_config,
                request_data
            )
        
        return {
            "status": "triggered",
            "analysis_id": analysis_id,
            "message": "LLM ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ” /api/analysis/results-v2/ì— ì €ì¥ë©ë‹ˆë‹¤.",
            "mcp_method": "direct_import"
        }
        
    except Exception as e:
        logger.exception(f"âŒ LLM ë¶„ì„ V2 íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )


async def execute_mcp_analysis_and_save_v2(
    analysis_id: str,
    db_config: Dict[str, Any],
    request_data: Dict[str, Any]
):
    """
    MCP AnalysisServiceë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ V2 í˜•ì‹ìœ¼ë¡œ ì €ì¥
    
    Args:
        analysis_id: ë¶„ì„ ID
        db_config: PostgreSQL ì—°ê²° ì •ë³´
        request_data: ë¶„ì„ ìš”ì²­ ë°ì´í„°
    """
    try:
        logger.info(f"ğŸ”¬ MCP ë¶„ì„ ì‹¤í–‰ ì‹œì‘: {analysis_id}")
        
        # [1] PostgreSQLRepository ìƒì„±
        logger.info("ğŸ“¦ PostgreSQL Repository ìƒì„± ì¤‘...")
        db_repository = PostgreSQLRepository(
            host=db_config["host"],
            port=db_config["port"],
            user=db_config["user"],
            password=db_config["password"],
            dbname=db_config["dbname"]
        )
        
        # [2] AnalysisService ìƒì„± (MCPì˜ í•µì‹¬ ì„œë¹„ìŠ¤)
        logger.info("ğŸ§  AnalysisService ìƒì„± ì¤‘...")
        analysis_service = AnalysisService(
            database_repository=db_repository,
            time_parser=TimeRangeParser(),
            data_processor=DataProcessor()
        )
        
        # [3] MCP ë¶„ì„ ìš”ì²­ ë°ì´í„° êµ¬ì„±
        mcp_request = {
            "n_minus_1": request_data.get("n_minus_1"),
            "n": request_data.get("n"),
            "table": db_config.get("table", "summary"),
            "analysis_id": analysis_id,
        }
        
        # ne_id ë˜ëŠ” cell_idê°€ ìˆìœ¼ë©´ filters ì¶”ê°€
        if request_data.get("ne_id") or request_data.get("cell_id"):
            mcp_request["filters"] = {}
            if request_data.get("ne_id"):
                mcp_request["filters"]["ne"] = request_data.get("ne_id")
            if request_data.get("cell_id"):
                mcp_request["filters"]["cellid"] = request_data.get("cell_id")
        
        logger.info(f"ğŸ“‹ MCP ìš”ì²­ ë°ì´í„°: n_minus_1={mcp_request['n_minus_1']}, "
                   f"n={mcp_request['n']}, table={mcp_request.get('table')}")
        
        # [4] MCP ë¶„ì„ ì‹¤í–‰ (ë™ê¸° í•¨ìˆ˜)
        logger.info("âš¡ MCP ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        mcp_result = analysis_service.perform_analysis(mcp_request)
        
        logger.info(f"âœ… MCP ë¶„ì„ ì™„ë£Œ: {analysis_id}")
        logger.debug(f"ğŸ“Š MCP ê²°ê³¼ í‚¤: {list(mcp_result.keys())}")
        
        # [5] V2 í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ë° ì €ì¥
        logger.info("ğŸ’¾ V2 í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì¤‘...")
        db = get_database()
        v2_collection = db.analysis_results_v2
        
        # MCP ê²°ê³¼ë¥¼ V2 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        v2_payload = convert_mcp_result_to_v2_format(
            mcp_result,
            analysis_id,
            request_data
        )
        
        # MongoDBì— ì €ì¥
        result = await v2_collection.insert_one(v2_payload)
        
        logger.info(f"ğŸ’¿ V2 ê²°ê³¼ ì €ì¥ ì™„ë£Œ: analysis_id={analysis_id}, "
                   f"mongodb_id={result.inserted_id}")
        
        # [6] Repository ì •ë¦¬
        db_repository.close()
        logger.info(f"ğŸ ë¶„ì„ ì™„ë£Œ: {analysis_id}")
        
    except AnalysisServiceError as e:
        logger.error(f"âŒ MCP ë¶„ì„ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {analysis_id}, {e}")
        await save_analysis_error_v2(analysis_id, str(e), "mcp_analysis_error")
    except Exception as e:
        logger.exception(f"âŒ MCP ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {analysis_id}, {e}")
        await save_analysis_error_v2(analysis_id, str(e), "unexpected_error")


def convert_mcp_result_to_v2_format(
    mcp_result: Dict[str, Any],
    analysis_id: str,
    request_data: Dict[str, Any]
) -> Dict[str, Any]:
    """
    MCP ë¶„ì„ ê²°ê³¼ë¥¼ V2 API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    Args:
        mcp_result: MCP AnalysisService.perform_analysis() ê²°ê³¼
        analysis_id: ë¶„ì„ ID
        request_data: ì›ë³¸ ìš”ì²­ ë°ì´í„°
        
    Returns:
        V2 í˜•ì‹ì˜ í˜ì´ë¡œë“œ
    """
    logger.debug("ğŸ”„ MCP ê²°ê³¼ â†’ V2 í˜•ì‹ ë³€í™˜ ì‹œì‘")
    
    # MCP ê²°ê³¼ êµ¬ì¡° í™•ì¸
    source_metadata = mcp_result.get("source_metadata", {})
    llm_analysis = mcp_result.get("llm_analysis", {})
    peg_comparisons = mcp_result.get("peg_comparisons", [])
    choi_result = mcp_result.get("choi_result", {})
    
    # ì‹œê°„ ë²”ìœ„ íŒŒì‹±
    analysis_period = {}
    if "time_ranges" in mcp_result:
        time_ranges = mcp_result["time_ranges"]
        n_minus_1 = time_ranges.get("n_minus_1", {})
        n = time_ranges.get("n", {})
        
        analysis_period = {
            "n_minus_1_start": n_minus_1.get("start", ""),
            "n_minus_1_end": n_minus_1.get("end", ""),
            "n_start": n.get("start", ""),
            "n_end": n.get("end", "")
        }
    
    # V2 í˜ì´ë¡œë“œ êµ¬ì„±
    v2_payload = {
        "analysis_id": analysis_id,
        "ne_id": source_metadata.get("ne_id", request_data.get("ne_id", "All NEs")),
        "cell_id": str(source_metadata.get("cell_id", request_data.get("cell_id", "All cells"))),
        "swname": source_metadata.get("swname", request_data.get("swname", "Unknown")),
        "rel_ver": source_metadata.get("rel_ver"),
        "analysis_period": analysis_period,
        "choi_result": {
            "enabled": bool(choi_result),
            "status": choi_result.get("overall", "unknown") if choi_result else "not_run",
            "score": choi_result.get("score"),
            "reasons": choi_result.get("reasons", [])
        } if choi_result else None,
        "llm_analysis": llm_analysis,
        "peg_comparisons": peg_comparisons,
        "created_at": datetime.utcnow(),
        "metadata": mcp_result.get("metadata", {})
    }
    
    logger.debug(f"âœ… V2 ë³€í™˜ ì™„ë£Œ: ne_id={v2_payload['ne_id']}, "
                f"cell_id={v2_payload['cell_id']}, "
                f"peg_count={len(peg_comparisons)}")
    
    return v2_payload


async def save_analysis_error_v2(
    analysis_id: str,
    error_message: str,
    error_type: str = "unknown"
):
    """
    ë¶„ì„ ì˜¤ë¥˜ë¥¼ V2 í˜•ì‹ìœ¼ë¡œ ì €ì¥
    
    Args:
        analysis_id: ë¶„ì„ ID
        error_message: ì˜¤ë¥˜ ë©”ì‹œì§€
        error_type: ì˜¤ë¥˜ ìœ í˜•
    """
    try:
        db = get_database()
        v2_collection = db.analysis_results_v2
        
        error_payload = {
            "analysis_id": analysis_id,
            "ne_id": "error",
            "cell_id": "error",
            "swname": "error",
            "rel_ver": None,
            "analysis_period": {},
            "choi_result": None,
            "llm_analysis": {
                "error": error_message,
                "error_type": error_type
            },
            "peg_comparisons": [],
            "created_at": datetime.utcnow(),
            "metadata": {
                "status": "error",
                "error_message": error_message,
                "error_type": error_type
            }
        }
        
        await v2_collection.insert_one(error_payload)
        logger.info(f"ğŸ”´ ì˜¤ë¥˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ: {analysis_id}")
        
    except Exception as e:
        logger.exception(f"ì˜¤ë¥˜ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {analysis_id}, {e}")

