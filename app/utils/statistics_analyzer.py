"""
Statistics ë¹„êµ ë¶„ì„ì„ ìœ„í•œ Pandas ê¸°ë°˜ í†µê³„ ë¶„ì„ ìœ í‹¸ë¦¬í‹°

ì´ ëª¨ë“ˆì€ ì¡°íšŒëœ KPI ë°ì´í„°ë¥¼ Pandasë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ë¦¬í•˜ê³ ,
í†µê³„ ë¶„ì„(í‰ê· , Delta, RSD, t-ê²€ì • ë“±)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from scipy import stats
import logging

from ..models.statistics import (
    PegStatistics, PegComparisonResult, 
    calculate_improvement_status, calculate_improvement_magnitude
)

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

class StatisticsAnalyzer:
    """Pandas ê¸°ë°˜ í†µê³„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, decimal_places: int = 4):
        """
        í†µê³„ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            decimal_places: ì†Œìˆ˜ì  ìë¦¿ìˆ˜ (ê¸°ë³¸ê°’: 4)
        """
        self.decimal_places = decimal_places
        
    def round_value(self, value: float) -> float:
        """ê°’ì„ ì§€ì •ëœ ì†Œìˆ˜ì  ìë¦¿ìˆ˜ë¡œ ë°˜ì˜¬ë¦¼"""
        if pd.isna(value) or not np.isfinite(value):
            return 0.0
        return round(float(value), self.decimal_places)
    
    def calculate_basic_statistics(self, data: List[Dict[str, Any]]) -> Dict[str, PegStatistics]:
        """
        ê¸°ë³¸ í†µê³„ ê³„ì‚° (í‰ê· , í‘œì¤€í¸ì°¨, ìµœëŒ€/ìµœì†Œê°’ ë“±)
        
        Args:
            data: KPI ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            PEGë³„ ê¸°ë³¸ í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        try:
            logger.info(f"ê¸°ë³¸ í†µê³„ ê³„ì‚° ì‹œì‘ - ë°ì´í„° í¬ì¸íŠ¸: {len(data)}ê°œ")
            
            if not data:
                logger.warning("ë°ì´í„°ê°€ ì—†ì–´ ë¹ˆ í†µê³„ ë°˜í™˜")
                return {}
            
            # DataFrame ìƒì„±
            df = pd.DataFrame(data)
            
            # ìˆ«ì ë³€í™˜
            df['value_numeric'] = pd.to_numeric(df['value'], errors='coerce')
            
            # NaN ê°’ ì œê±°
            df = df.dropna(subset=['value_numeric'])
            
            if df.empty:
                logger.warning("ìœ íš¨í•œ ìˆ«ì ë°ì´í„°ê°€ ì—†ìŒ")
                return {}
            
            logger.info(f"ìœ íš¨í•œ ë°ì´í„° í¬ì¸íŠ¸: {len(df)}ê°œ")
            
            # PEGë³„ í†µê³„ ê³„ì‚°
            peg_stats = {}
            
            for peg_name in df['peg_name'].unique():
                peg_data = df[df['peg_name'] == peg_name]['value_numeric']
                
                if len(peg_data) == 0:
                    continue
                
                # ê¸°ë³¸ í†µê³„ ê³„ì‚°
                stats_dict = {
                    'count': len(peg_data),
                    'mean': self.round_value(peg_data.mean()),
                    'std': self.round_value(peg_data.std()),
                    'min': self.round_value(peg_data.min()),
                    'max': self.round_value(peg_data.max())
                }
                
                # ë¶„ìœ„ìˆ˜ ê³„ì‚° (ë°ì´í„°ê°€ ì¶©ë¶„í•œ ê²½ìš°)
                if len(peg_data) >= 4:
                    stats_dict.update({
                        'median': self.round_value(peg_data.median()),
                        'percentile_25': self.round_value(peg_data.quantile(0.25)),
                        'percentile_75': self.round_value(peg_data.quantile(0.75))
                    })
                else:
                    stats_dict.update({
                        'median': stats_dict['mean'],
                        'percentile_25': stats_dict['min'],
                        'percentile_75': stats_dict['max']
                    })
                
                peg_stats[peg_name] = PegStatistics(**stats_dict)
                
                logger.info(f"PEG '{peg_name}' í†µê³„ ê³„ì‚° ì™„ë£Œ - ë°ì´í„°: {len(peg_data)}ê°œ")
            
            logger.info(f"ê¸°ë³¸ í†µê³„ ê³„ì‚° ì™„ë£Œ - PEG ìˆ˜: {len(peg_stats)}")
            return peg_stats
            
        except Exception as e:
            logger.error(f"ê¸°ë³¸ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            raise
    
    def calculate_comparison_statistics(
        self,
        period1_data: List[Dict[str, Any]],
        period2_data: List[Dict[str, Any]],
        peg_names: List[str]
    ) -> List[PegComparisonResult]:
        """
        ë‘ ê¸°ê°„ì˜ ë¹„êµ í†µê³„ ê³„ì‚°
        
        Args:
            period1_data: ì²« ë²ˆì§¸ ê¸°ê°„ ë°ì´í„°
            period2_data: ë‘ ë²ˆì§¸ ê¸°ê°„ ë°ì´í„°
            peg_names: ë¶„ì„í•  PEG ì´ë¦„ ëª©ë¡
            
        Returns:
            PEGë³„ ë¹„êµ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            logger.info("ë¹„êµ í†µê³„ ê³„ì‚° ì‹œì‘")
            
            # ê° ê¸°ê°„ì˜ ê¸°ë³¸ í†µê³„ ê³„ì‚°
            period1_stats = self.calculate_basic_statistics(period1_data)
            period2_stats = self.calculate_basic_statistics(period2_data)
            
            comparison_results = []
            
            for peg_name in peg_names:
                try:
                    # ë‘ ê¸°ê°„ ëª¨ë‘ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                    if peg_name not in period1_stats or peg_name not in period2_stats:
                        logger.warning(f"PEG '{peg_name}'ì˜ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¹„êµ ë¶„ì„ ìƒëµ")
                        continue
                    
                    p1_stats = period1_stats[peg_name]
                    p2_stats = period2_stats[peg_name]
                    
                    # Delta ê³„ì‚°
                    delta = self.round_value(p2_stats.mean - p1_stats.mean)
                    
                    # Delta ë°±ë¶„ìœ¨ ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
                    if p1_stats.mean != 0:
                        delta_percentage = self.round_value((delta / abs(p1_stats.mean)) * 100)
                    else:
                        delta_percentage = 0.0
                    
                    # RSD (ìƒëŒ€í‘œì¤€í¸ì°¨) ê³„ì‚°
                    rsd_period1 = self.calculate_rsd(p1_stats.mean, p1_stats.std)
                    rsd_period2 = self.calculate_rsd(p2_stats.mean, p2_stats.std)
                    
                    # í†µê³„ì  ìœ ì˜ì„± ê²€ì • (t-test)
                    t_stat, p_value, is_significant = self.perform_t_test(
                        period1_data, period2_data, peg_name
                    )
                    
                    # ê°œì„  ìƒíƒœ ë° ì •ë„ ê³„ì‚°
                    improvement_status = calculate_improvement_status(delta, peg_name)
                    improvement_magnitude = calculate_improvement_magnitude(abs(delta_percentage))
                    
                    # ë¹„êµ ê²°ê³¼ ìƒì„±
                    comparison_result = PegComparisonResult(
                        peg_name=peg_name,
                        period1_stats=p1_stats,
                        period2_stats=p2_stats,
                        delta=delta,
                        delta_percentage=delta_percentage,
                        rsd_period1=rsd_period1,
                        rsd_period2=rsd_period2,
                        t_statistic=t_stat,
                        p_value=p_value,
                        is_significant=is_significant,
                        improvement_status=improvement_status,
                        improvement_magnitude=improvement_magnitude
                    )
                    
                    comparison_results.append(comparison_result)
                    
                    logger.info(f"PEG '{peg_name}' ë¹„êµ ë¶„ì„ ì™„ë£Œ - Delta: {delta}, ìƒíƒœ: {improvement_status}")
                    
                except Exception as e:
                    logger.error(f"PEG '{peg_name}' ë¹„êµ ë¶„ì„ ì‹¤íŒ¨: {e}")
                    continue
            
            logger.info(f"ë¹„êµ í†µê³„ ê³„ì‚° ì™„ë£Œ - ë¶„ì„ëœ PEG: {len(comparison_results)}ê°œ")
            return comparison_results
            
        except Exception as e:
            logger.error(f"ë¹„êµ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            raise
    
    def calculate_rsd(self, mean: float, std: float) -> float:
        """
        RSD (ìƒëŒ€í‘œì¤€í¸ì°¨) ê³„ì‚°
        
        Args:
            mean: í‰ê· ê°’
            std: í‘œì¤€í¸ì°¨
            
        Returns:
            RSD ë°±ë¶„ìœ¨ ê°’
        """
        if mean == 0 or pd.isna(mean) or pd.isna(std):
            return 0.0
        
        rsd = (std / abs(mean)) * 100
        return self.round_value(rsd)
    
    def perform_t_test(
        self,
        period1_data: List[Dict[str, Any]],
        period2_data: List[Dict[str, Any]],
        peg_name: str,
        alpha: float = 0.05
    ) -> Tuple[Optional[float], Optional[float], Optional[bool]]:
        """
        ë‘ ê¸°ê°„ ë°ì´í„°ì— ëŒ€í•œ t-ê²€ì • ìˆ˜í–‰
        
        Args:
            period1_data: ì²« ë²ˆì§¸ ê¸°ê°„ ë°ì´í„°
            period2_data: ë‘ ë²ˆì§¸ ê¸°ê°„ ë°ì´í„°
            peg_name: PEG ì´ë¦„
            alpha: ìœ ì˜ìˆ˜ì¤€ (ê¸°ë³¸ê°’: 0.05)
            
        Returns:
            (t_statistic, p_value, is_significant) íŠœí”Œ
        """
        try:
            # PEGë³„ ë°ì´í„° ì¶”ì¶œ
            p1_values = [
                float(item['value']) for item in period1_data 
                if item['peg_name'] == peg_name and pd.notna(item['value'])
            ]
            
            p2_values = [
                float(item['value']) for item in period2_data
                if item['peg_name'] == peg_name and pd.notna(item['value'])
            ]
            
            # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ í™•ì¸
            if len(p1_values) < 3 or len(p2_values) < 3:
                logger.warning(f"PEG '{peg_name}' t-ê²€ì •ìš© ë°ì´í„° ë¶€ì¡±")
                return None, None, None
            
            # ë…ë¦½í‘œë³¸ t-ê²€ì • ìˆ˜í–‰
            t_statistic, p_value = stats.ttest_ind(p1_values, p2_values)
            
            # ìœ ì˜ì„± íŒì •
            is_significant = p_value < alpha
            
            return (
                self.round_value(t_statistic),
                self.round_value(p_value),
                is_significant
            )
            
        except Exception as e:
            logger.error(f"PEG '{peg_name}' t-ê²€ì • ì‹¤íŒ¨: {e}")
            return None, None, None
    
    def calculate_summary_statistics(
        self,
        comparison_results: List[PegComparisonResult]
    ) -> Dict[str, Any]:
        """
        ì „ì²´ ë¹„êµ ê²°ê³¼ì˜ ìš”ì•½ í†µê³„ ê³„ì‚°
        
        Args:
            comparison_results: PEGë³„ ë¹„êµ ë¶„ì„ ê²°ê³¼
            
        Returns:
            ìš”ì•½ í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        try:
            logger.info("ìš”ì•½ í†µê³„ ê³„ì‚° ì‹œì‘")
            
            if not comparison_results:
                return {
                    "total_pegs_analyzed": 0,
                    "improved_count": 0,
                    "degraded_count": 0,
                    "stable_count": 0,
                    "avg_improvement": 0.0,
                    "significant_changes": 0,
                    "max_improvement": 0.0,
                    "max_degradation": 0.0
                }
            
            # ìƒíƒœë³„ ì¹´ìš´íŠ¸
            status_counts = {
                'improved': 0,
                'degraded': 0,
                'stable': 0
            }
            
            # ë¸íƒ€ ë° ìœ ì˜ì„± í†µê³„
            deltas = []
            significant_changes = 0
            
            for result in comparison_results:
                status_counts[result.improvement_status] += 1
                deltas.append(result.delta_percentage)
                
                if result.is_significant:
                    significant_changes += 1
            
            # ìš”ì•½ í†µê³„ ê³„ì‚°
            summary = {
                "total_pegs_analyzed": len(comparison_results),
                "improved_count": status_counts['improved'],
                "degraded_count": status_counts['degraded'],
                "stable_count": status_counts['stable'],
                "avg_improvement": self.round_value(np.mean(deltas)),
                "significant_changes": significant_changes,
                "max_improvement": self.round_value(max(deltas)) if deltas else 0.0,
                "max_degradation": self.round_value(min(deltas)) if deltas else 0.0,
                "std_delta": self.round_value(np.std(deltas)) if len(deltas) > 1 else 0.0
            }
            
            logger.info(f"ìš”ì•½ í†µê³„ ê³„ì‚° ì™„ë£Œ: {summary}")
            return summary
            
        except Exception as e:
            logger.error(f"ìš”ì•½ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            raise
    
    def detect_outliers(
        self,
        data: List[Dict[str, Any]],
        method: str = 'iqr'
    ) -> Dict[str, List[int]]:
        """
        ì´ìƒì¹˜ íƒì§€
        
        Args:
            data: KPI ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            method: íƒì§€ ë°©ë²• ('iqr', 'zscore')
            
        Returns:
            PEGë³„ ì´ìƒì¹˜ ì¸ë±ìŠ¤ ë”•ì…”ë„ˆë¦¬
        """
        try:
            logger.info(f"ì´ìƒì¹˜ íƒì§€ ì‹œì‘ - ë°©ë²•: {method}")
            
            if not data:
                return {}
            
            df = pd.DataFrame(data)
            df['value_numeric'] = pd.to_numeric(df['value'], errors='coerce')
            df = df.dropna(subset=['value_numeric'])
            
            outliers = {}
            
            for peg_name in df['peg_name'].unique():
                peg_data = df[df['peg_name'] == peg_name]
                peg_outliers = []
                
                if method == 'iqr':
                    # IQR ë°©ë²•
                    Q1 = peg_data['value_numeric'].quantile(0.25)
                    Q3 = peg_data['value_numeric'].quantile(0.75)
                    IQR = Q3 - Q1
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    
                    outlier_mask = (
                        (peg_data['value_numeric'] < lower_bound) |
                        (peg_data['value_numeric'] > upper_bound)
                    )
                    
                elif method == 'zscore':
                    # Z-Score ë°©ë²•
                    z_scores = np.abs(stats.zscore(peg_data['value_numeric']))
                    outlier_mask = z_scores > 3
                
                else:
                    logger.error(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ìƒì¹˜ íƒì§€ ë°©ë²•: {method}")
                    continue
                
                peg_outliers = peg_data[outlier_mask].index.tolist()
                outliers[peg_name] = peg_outliers
                
                logger.info(f"PEG '{peg_name}' ì´ìƒì¹˜: {len(peg_outliers)}ê°œ")
            
            return outliers
            
        except Exception as e:
            logger.error(f"ì´ìƒì¹˜ íƒì§€ ì‹¤íŒ¨: {e}")
            raise
    
    def generate_analysis_metadata(
        self,
        start_time: datetime,
        period1_data_count: int,
        period2_data_count: int,
        peg_names: List[str],
        filters_applied: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ë¶„ì„ ë©”íƒ€ë°ì´í„° ìƒì„±
        
        Args:
            start_time: ë¶„ì„ ì‹œì‘ ì‹œê°„
            period1_data_count: ê¸°ê°„1 ë°ì´í„° ìˆ˜
            period2_data_count: ê¸°ê°„2 ë°ì´í„° ìˆ˜  
            peg_names: ìš”ì²­ëœ PEG ëª©ë¡
            filters_applied: ì ìš©ëœ í•„í„° ì •ë³´
            
        Returns:
            ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        end_time = datetime.utcnow()
        processing_time = (end_time - start_time).total_seconds() * 1000
        
        metadata = {
            "analysis_timestamp": end_time.isoformat() + "Z",
            "processing_time_ms": round(processing_time, 2),
            "data_source": "mongodb",
            "decimal_places": self.decimal_places,
            "period1_data_count": period1_data_count,
            "period2_data_count": period2_data_count,
            "requested_pegs": peg_names,
            "filters_applied": filters_applied,
            "analysis_version": "1.0.0"
        }
        
        return metadata

def validate_data_consistency(
    period1_data: List[Dict[str, Any]],
    period2_data: List[Dict[str, Any]],
    peg_names: List[str]
) -> Dict[str, Any]:
    """
    ë‘ ê¸°ê°„ ë°ì´í„°ì˜ ì¼ê´€ì„± ê²€ì¦
    
    Args:
        period1_data: ì²« ë²ˆì§¸ ê¸°ê°„ ë°ì´í„°
        period2_data: ë‘ ë²ˆì§¸ ê¸°ê°„ ë°ì´í„°
        peg_names: ìš”ì²­ëœ PEG ëª©ë¡
        
    Returns:
        ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ ê²°ê³¼
    """
    try:
        logger.info("ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ ì‹œì‘")
        
        # ê¸°ê°„ë³„ PEG ê°€ìš©ì„± í™•ì¸
        p1_pegs = set(item['peg_name'] for item in period1_data)
        p2_pegs = set(item['peg_name'] for item in period2_data)
        
        common_pegs = p1_pegs & p2_pegs
        missing_from_p1 = p2_pegs - p1_pegs
        missing_from_p2 = p1_pegs - p2_pegs
        
        # ìš”ì²­ëœ PEG ì¤‘ ì‚¬ìš© ê°€ëŠ¥í•œ ê²ƒë“¤
        available_pegs = common_pegs & set(peg_names)
        unavailable_pegs = set(peg_names) - available_pegs
        
        validation_result = {
            "is_consistent": len(unavailable_pegs) == 0,
            "common_pegs": list(common_pegs),
            "available_pegs": list(available_pegs),
            "unavailable_pegs": list(unavailable_pegs),
            "missing_from_period1": list(missing_from_p1),
            "missing_from_period2": list(missing_from_p2),
            "period1_data_count": len(period1_data),
            "period2_data_count": len(period2_data)
        }
        
        logger.info(f"ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ ì™„ë£Œ: {validation_result['is_consistent']}")
        return validation_result
        
    except Exception as e:
        logger.error(f"ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    import random
    from datetime import timedelta
    
    def generate_test_data(peg_names: List[str], count: int) -> List[Dict[str, Any]]:
        """í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±"""
        base_date = datetime(2025, 8, 1)
        data = []
        
        for i in range(count):
            for peg in peg_names:
                data.append({
                    'timestamp': base_date + timedelta(hours=i),
                    'peg_name': peg,
                    'value': random.gauss(99.0, 1.0),
                    'ne': f'nvgnb#{random.randint(10000, 30000)}',
                    'cell_id': f'20{random.randint(10, 19)}'
                })
        
        return data
    
    # ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸
    analyzer = StatisticsAnalyzer(decimal_places=4)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_pegs = ['availability', 'rrc', 'erab']
    period1_data = generate_test_data(test_pegs, 100)
    period2_data = generate_test_data(test_pegs, 100)
    
    # ë¹„êµ ë¶„ì„ ìˆ˜í–‰
    results = analyzer.calculate_comparison_statistics(period1_data, period2_data, test_pegs)
    summary = analyzer.calculate_summary_statistics(results)
    
    print(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ë¶„ì„ëœ PEG: {len(results)}ê°œ")
    print(f"ğŸ“Š ìš”ì•½: {summary}")

