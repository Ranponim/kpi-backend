"""
Statistics ë¹„êµ ë¶„ì„ API ë° ë¡œì§ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

ì´ ëª¨ë“ˆì€ Statistics ë¹„êµ ë¶„ì„ ê¸°ëŠ¥ì˜ ì •í™•ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ
í¬ê´„ì ì¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import pytest
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Any
import numpy as np
import pandas as pd

from app.models.statistics import (
    StatisticsCompareRequest, DateRange, PegStatistics, PegComparisonResult,
    calculate_improvement_status, calculate_improvement_magnitude
)
from app.utils.statistics_analyzer import StatisticsAnalyzer, validate_data_consistency
from app.utils.statistics_db import StatisticsDataBase
import logging

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

class TestStatisticsModels:
    """Statistics Pydantic ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    
    def test_date_range_validation(self):
        """ë‚ ì§œ ë²”ìœ„ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        
        # ì •ìƒì ì¸ ë‚ ì§œ ë²”ìœ„
        valid_range = DateRange(
            start_date=datetime(2025, 8, 1),
            end_date=datetime(2025, 8, 7)
        )
        assert valid_range.start_date < valid_range.end_date
        
        # ì˜ëª»ëœ ë‚ ì§œ ë²”ìœ„ (ì¢…ë£Œì¼ì´ ì‹œì‘ì¼ë³´ë‹¤ ì´ì „)
        with pytest.raises(ValueError, match="ì¢…ë£Œ ë‚ ì§œëŠ” ì‹œì‘ ë‚ ì§œë³´ë‹¤ ì´í›„ì—¬ì•¼ í•©ë‹ˆë‹¤"):
            DateRange(
                start_date=datetime(2025, 8, 7),
                end_date=datetime(2025, 8, 1)
            )
    
    def test_statistics_compare_request_validation(self):
        """ë¹„êµ ë¶„ì„ ìš”ì²­ ëª¨ë¸ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        
        # ì •ìƒì ì¸ ìš”ì²­
        valid_request = StatisticsCompareRequest(
            period1=DateRange(
                start_date=datetime(2025, 8, 1),
                end_date=datetime(2025, 8, 7)
            ),
            period2=DateRange(
                start_date=datetime(2025, 8, 8),
                end_date=datetime(2025, 8, 14)
            ),
            peg_names=["availability", "rrc", "erab"]
        )
        assert len(valid_request.peg_names) == 3
        assert valid_request.decimal_places == 4  # ê¸°ë³¸ê°’
        assert valid_request.include_outliers is True  # ê¸°ë³¸ê°’
        
        # ë¹ˆ PEG ëª©ë¡ (ì—ëŸ¬)
        with pytest.raises(ValueError):
            StatisticsCompareRequest(
                period1=DateRange(
                    start_date=datetime(2025, 8, 1),
                    end_date=datetime(2025, 8, 7)
                ),
                period2=DateRange(
                    start_date=datetime(2025, 8, 8),
                    end_date=datetime(2025, 8, 14)
                ),
                peg_names=[]  # ë¹ˆ ëª©ë¡
            )

class TestImprovementCalculations:
    """ê°œì„  ìƒíƒœ ë° ì •ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
    
    def test_improvement_status_calculation(self):
        """ê°œì„  ìƒíƒœ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        
        # ë†’ì„ìˆ˜ë¡ ì¢‹ì€ PEG (availability)
        assert calculate_improvement_status(0.5, "availability") == "improved"
        assert calculate_improvement_status(-0.3, "availability") == "degraded"
        assert calculate_improvement_status(0.0, "availability") == "stable"
        
        # ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ PEG (latency)
        assert calculate_improvement_status(-0.5, "latency") == "improved"
        assert calculate_improvement_status(0.3, "latency") == "degraded"
        assert calculate_improvement_status(0.0, "latency") == "stable"
        
        # ì•Œ ìˆ˜ ì—†ëŠ” PEG (ê¸°ë³¸ì ìœ¼ë¡œ ì¦ê°€=ê°œì„ )
        assert calculate_improvement_status(0.1, "unknown_peg") == "improved"
        assert calculate_improvement_status(-0.1, "unknown_peg") == "degraded"
    
    def test_improvement_magnitude_calculation(self):
        """ê°œì„  ì •ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        
        assert calculate_improvement_magnitude(10.0) == "significant"  # > 5%
        assert calculate_improvement_magnitude(3.0) == "moderate"      # 1-5%
        assert calculate_improvement_magnitude(0.5) == "minor"         # 0.1-1%
        assert calculate_improvement_magnitude(0.05) == "none"         # < 0.1%
        
        # ìŒìˆ˜ ê°’ë„ ì ˆëŒ“ê°’ìœ¼ë¡œ ì²˜ë¦¬
        assert calculate_improvement_magnitude(-8.0) == "significant"

class TestStatisticsAnalyzer:
    """StatisticsAnalyzer í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def analyzer(self):
        """í…ŒìŠ¤íŠ¸ìš© ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤"""
        return StatisticsAnalyzer(decimal_places=3)
    
    @pytest.fixture
    def sample_data(self):
        """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°"""
        base_date = datetime(2025, 8, 1)
        data = []
        
        # availability ë°ì´í„° (99.0 Â± 0.5)
        for i in range(100):
            data.append({
                'timestamp': base_date + timedelta(hours=i),
                'peg_name': 'availability',
                'value': 99.0 + np.random.normal(0, 0.5),
                'ne': 'nvgnb#10000',
                'cell_id': '2010'
            })
        
        # rrc ë°ì´í„° (98.5 Â± 1.0) 
        for i in range(100):
            data.append({
                'timestamp': base_date + timedelta(hours=i),
                'peg_name': 'rrc',
                'value': 98.5 + np.random.normal(0, 1.0),
                'ne': 'nvgnb#10000',
                'cell_id': '2010'
            })
        
        return data
    
    def test_basic_statistics_calculation(self, analyzer, sample_data):
        """ê¸°ë³¸ í†µê³„ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        
        stats = analyzer.calculate_basic_statistics(sample_data)
        
        # availability í†µê³„ í™•ì¸
        availability_stats = stats['availability']
        assert isinstance(availability_stats, PegStatistics)
        assert availability_stats.count == 100
        assert 98.0 <= availability_stats.mean <= 100.0  # ëŒ€ëµì ì¸ ë²”ìœ„
        assert availability_stats.std > 0
        assert availability_stats.min <= availability_stats.mean <= availability_stats.max
        
        # rrc í†µê³„ í™•ì¸
        rrc_stats = stats['rrc']
        assert isinstance(rrc_stats, PegStatistics)
        assert rrc_stats.count == 100
        assert 97.0 <= rrc_stats.mean <= 100.0
    
    def test_rsd_calculation(self, analyzer):
        """RSD (ìƒëŒ€í‘œì¤€í¸ì°¨) ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        
        # ì •ìƒ ì¼€ì´ìŠ¤
        rsd = analyzer.calculate_rsd(100.0, 2.0)
        assert rsd == 2.0  # (2/100) * 100 = 2%
        
        # í‰ê· ì´ 0ì¸ ê²½ìš°
        rsd_zero = analyzer.calculate_rsd(0.0, 1.0)
        assert rsd_zero == 0.0
        
        # NaN ê°’ ì²˜ë¦¬
        rsd_nan = analyzer.calculate_rsd(float('nan'), 1.0)
        assert rsd_nan == 0.0
    
    def test_comparison_statistics(self, analyzer):
        """ë¹„êµ í†µê³„ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        
        # ê¸°ê°„1 ë°ì´í„° (í‰ê·  99.0)
        period1_data = []
        for i in range(50):
            period1_data.append({
                'peg_name': 'availability',
                'value': 99.0 + np.random.normal(0, 0.1),
                'timestamp': datetime(2025, 8, 1) + timedelta(hours=i)
            })
        
        # ê¸°ê°„2 ë°ì´í„° (í‰ê·  99.5 - ê°œì„ ë¨)
        period2_data = []
        for i in range(50):
            period2_data.append({
                'peg_name': 'availability',
                'value': 99.5 + np.random.normal(0, 0.1),
                'timestamp': datetime(2025, 8, 8) + timedelta(hours=i)
            })
        
        results = analyzer.calculate_comparison_statistics(
            period1_data, period2_data, ['availability']
        )
        
        assert len(results) == 1
        
        result = results[0]
        assert isinstance(result, PegComparisonResult)
        assert result.peg_name == 'availability'
        assert result.delta > 0  # ê°œì„ ë˜ì—ˆìœ¼ë¯€ë¡œ ì–‘ìˆ˜
        assert result.improvement_status == 'improved'
        assert result.period1_stats.count == 50
        assert result.period2_stats.count == 50
    
    def test_summary_statistics(self, analyzer):
        """ìš”ì•½ í†µê³„ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        
        # ìƒ˜í”Œ ë¹„êµ ê²°ê³¼ ìƒì„±
        comparison_results = [
            PegComparisonResult(
                peg_name="availability",
                period1_stats=PegStatistics(count=100, mean=99.0, std=0.5, min=98.0, max=99.8),
                period2_stats=PegStatistics(count=100, mean=99.3, std=0.4, min=98.5, max=99.9),
                delta=0.3,
                delta_percentage=0.303,
                rsd_period1=0.505,
                rsd_period2=0.404,
                improvement_status="improved",
                improvement_magnitude="minor"
            ),
            PegComparisonResult(
                peg_name="rrc",
                period1_stats=PegStatistics(count=100, mean=98.5, std=1.0, min=96.0, max=99.5),
                period2_stats=PegStatistics(count=100, mean=98.2, std=0.8, min=96.5, max=99.2),
                delta=-0.3,
                delta_percentage=-0.305,
                rsd_period1=1.015,
                rsd_period2=0.815,
                improvement_status="degraded",
                improvement_magnitude="minor"
            )
        ]
        
        summary = analyzer.calculate_summary_statistics(comparison_results)
        
        assert summary["total_pegs_analyzed"] == 2
        assert summary["improved_count"] == 1
        assert summary["degraded_count"] == 1
        assert summary["stable_count"] == 0
        assert isinstance(summary["avg_improvement"], (int, float))

class TestDataValidation:
    """ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ í…ŒìŠ¤íŠ¸"""
    
    def test_data_consistency_validation(self):
        """ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        
        # ì¼ê´€ëœ ë°ì´í„°
        period1_data = [
            {'peg_name': 'availability', 'value': 99.0},
            {'peg_name': 'rrc', 'value': 98.5}
        ]
        
        period2_data = [
            {'peg_name': 'availability', 'value': 99.2},
            {'peg_name': 'rrc', 'value': 98.7},
            {'peg_name': 'erab', 'value': 99.1}  # ì¶”ê°€ PEG
        ]
        
        result = validate_data_consistency(period1_data, period2_data, ['availability', 'rrc'])
        
        assert 'availability' in result["common_pegs"]
        assert 'rrc' in result["common_pegs"]
        assert 'erab' in result["missing_from_period1"]
        assert result["period1_data_count"] == 2
        assert result["period2_data_count"] == 3
    
    def test_inconsistent_data_validation(self):
        """ì¼ê´€ì„± ì—†ëŠ” ë°ì´í„° ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        
        period1_data = [{'peg_name': 'availability', 'value': 99.0}]
        period2_data = [{'peg_name': 'rrc', 'value': 98.5}]
        
        result = validate_data_consistency(period1_data, period2_data, ['availability', 'rrc'])
        
        assert not result["is_consistent"]
        assert len(result["common_pegs"]) == 0
        assert 'availability' in result["missing_from_period2"]
        assert 'rrc' in result["missing_from_period1"]

class TestStatisticsIntegration:
    """í†µí•© í…ŒìŠ¤íŠ¸"""
    
    def generate_realistic_test_data(self, peg_name: str, base_value: float, 
                                   std: float, count: int, 
                                   period_start: datetime) -> List[Dict[str, Any]]:
        """í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±"""
        data = []
        
        for i in range(count):
            # ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ì¶”ê°€ (ì˜ˆ: í”¼í¬ ì‹œê°„ì—ëŠ” ì„±ëŠ¥ ì €í•˜)
            hour = (period_start + timedelta(hours=i)).hour
            if 9 <= hour <= 17:  # ì—…ë¬´ ì‹œê°„
                adjustment = -0.5  # ì„±ëŠ¥ ì €í•˜
            elif 22 <= hour or hour <= 6:  # ì‹¬ì•¼ ì‹œê°„
                adjustment = 0.3   # ì„±ëŠ¥ í–¥ìƒ
            else:
                adjustment = 0.0
            
            value = base_value + adjustment + np.random.normal(0, std)
            value = max(0, min(100, value))  # 0-100% ë²”ìœ„ ì œí•œ
            
            data.append({
                'timestamp': period_start + timedelta(hours=i),
                'peg_name': peg_name,
                'value': round(value, 4),
                'ne': f'nvgnb#{10000 + (i % 3) * 10000}',
                'cell_id': f'20{10 + (i % 10)}'
            })
        
        return data
    
    def test_full_analysis_workflow(self):
        """ì „ì²´ ë¶„ì„ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        
        analyzer = StatisticsAnalyzer(decimal_places=4)
        
        # í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        period1_start = datetime(2025, 8, 1)
        period2_start = datetime(2025, 8, 8)
        
        # ê¸°ê°„1: availability 99.5% (ì•ˆì •ì )
        period1_data = self.generate_realistic_test_data(
            'availability', 99.5, 0.3, 168, period1_start  # 7ì¼ * 24ì‹œê°„
        )
        
        # ê¸°ê°„2: availability 99.8% (ê°œì„ ë¨)
        period2_data = self.generate_realistic_test_data(
            'availability', 99.8, 0.2, 168, period2_start
        )
        
        # rrc ë°ì´í„°ë„ ì¶”ê°€
        period1_data.extend(
            self.generate_realistic_test_data('rrc', 98.5, 0.8, 168, period1_start)
        )
        period2_data.extend(
            self.generate_realistic_test_data('rrc', 98.2, 1.0, 168, period2_start)
        )
        
        # ë¹„êµ ë¶„ì„ ìˆ˜í–‰
        results = analyzer.calculate_comparison_statistics(
            period1_data, period2_data, ['availability', 'rrc']
        )
        
        # ê²°ê³¼ ê²€ì¦
        assert len(results) == 2
        
        # availability ê²°ê³¼ í™•ì¸
        avail_result = next(r for r in results if r.peg_name == 'availability')
        assert avail_result.improvement_status == 'improved'
        assert avail_result.delta > 0
        assert avail_result.period1_stats.count == 168
        assert avail_result.period2_stats.count == 168
        
        # rrc ê²°ê³¼ í™•ì¸ (ì•…í™”ë¨)
        rrc_result = next(r for r in results if r.peg_name == 'rrc')
        assert rrc_result.improvement_status == 'degraded'
        assert rrc_result.delta < 0
        
        # ìš”ì•½ í†µê³„ ìƒì„±
        summary = analyzer.calculate_summary_statistics(results)
        assert summary["total_pegs_analyzed"] == 2
        assert summary["improved_count"] == 1
        assert summary["degraded_count"] == 1
        
        logger.info(f"âœ… ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        logger.info(f"ğŸ“Š ê²°ê³¼: {summary}")

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
class TestPerformance:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.performance
    def test_large_dataset_performance(self):
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        import time
        
        analyzer = StatisticsAnalyzer()
        
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒì„± (1ë§Œê°œ í¬ì¸íŠ¸)
        large_data = []
        base_date = datetime(2025, 8, 1)
        
        for i in range(10000):
            large_data.append({
                'timestamp': base_date + timedelta(minutes=i),
                'peg_name': f'peg_{i % 5}',  # 5ê°œ PEG
                'value': 99.0 + np.random.normal(0, 1.0),
                'ne': f'nvgnb#{10000 + (i % 10) * 1000}',
                'cell_id': f'cell_{i % 20}'
            })
        
        # ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        stats = analyzer.calculate_basic_statistics(large_data)
        end_time = time.time()
        
        processing_time = end_time - start_time
        
        assert len(stats) == 5  # 5ê°œ PEG
        assert processing_time < 5.0  # 5ì´ˆ ì´ë‚´ ì²˜ë¦¬
        
        logger.info(f"ğŸ“ˆ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    pytest.main([__file__, "-v", "--tb=short"])

