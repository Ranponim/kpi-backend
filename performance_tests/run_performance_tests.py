#!/usr/bin/env python3
"""
ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

Locustë¥¼ ì‚¬ìš©í•˜ì—¬ ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ APIì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import subprocess
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from config import (
    TEST_SCENARIOS, PERFORMANCE_THRESHOLDS, REPORT_CONFIG,
    get_scenario_config, get_performance_thresholds
)


class PerformanceTestRunner:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°"""

    def __init__(self, backend_url: str = "http://localhost:8000"):
        self.backend_url = backend_url
        self.locust_file = Path(__file__).parent / "locustfile.py"
        self.results_dir = Path(__file__).parent / "results"
        self.results_dir.mkdir(exist_ok=True)

    def check_backend_health(self) -> bool:
        """ë°±ì—”ë“œ ì„œë²„ ìƒíƒœ í™•ì¸"""
        import requests

        try:
            response = requests.get(f"{self.backend_url}/health", timeout=10)
            if response.status_code == 200:
                data = response.json()
                return data.get("status") == "healthy"
        except Exception as e:
            print(f"âŒ ë°±ì—”ë“œ ì„œë²„ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

        return False

    def run_scenario(self, scenario_name: str) -> Dict[str, Any]:
        """íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
        print(f"ğŸš€ {scenario_name} ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        if not self.check_backend_health():
            raise RuntimeError("ë°±ì—”ë“œ ì„œë²„ê°€ ì •ìƒ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        scenario = get_scenario_config(scenario_name)
        user_class = scenario["user_class"]
        users = scenario["users"]
        spawn_rate = scenario["spawn_rate"]
        duration = scenario["duration"]

        # Locust ëª…ë ¹ì–´ êµ¬ì„±
        cmd = [
            "locust",
            "-f", str(self.locust_file),
            "--host", self.backend_url,
            "--users", str(users),
            "--spawn-rate", str(spawn_rate),
            "--run-time", f"{duration}s",
            "--headless",  # GUI ì—†ì´ ì‹¤í–‰
            "--only-summary",  # ìš”ì•½ë§Œ ì¶œë ¥
            "--json"  # JSON ì¶œë ¥
        ]

        # ì‚¬ìš©ì í´ë˜ìŠ¤ ì§€ì • (ê¸°ë³¸ê°’ ì™¸ì˜ ê²½ìš°)
        if user_class != "MahalanobisAnalysisUser":
            cmd.extend(["--class-picker", user_class])

        print(f"ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}")

        try:
            # Locust ì‹¤í–‰
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=Path(__file__).parent
            )

            if result.returncode == 0:
                print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
                return self.parse_locust_output(result.stdout, result.stderr)
            else:
                print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (ì½”ë“œ: {result.returncode})")
                print("STDOUT:", result.stdout)
                print("STDERR:", result.stderr)
                return {"error": f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result.stderr}"}

        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def parse_locust_output(self, stdout: str, stderr: str) -> Dict[str, Any]:
        """Locust ì¶œë ¥ íŒŒì‹±"""
        result = {
            "timestamp": datetime.now().isoformat(),
            "summary": {},
            "errors": [],
            "raw_output": stdout
        }

        # ê°„ë‹¨í•œ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
        lines = stdout.split('\n')

        for line in lines:
            if "Requests/sec" in line and "Failures/sec" in line:
                # ìš”ì•½ ë¼ì¸ íŒŒì‹±
                parts = line.split()
                if len(parts) >= 8:
                    result["summary"] = {
                        "requests_per_second": float(parts[1]),
                        "failures_per_second": float(parts[3]),
                        "response_time_50p": float(parts[5]),
                        "response_time_95p": float(parts[7])
                    }

        return result

    def validate_performance(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """ì„±ëŠ¥ ê¸°ì¤€ì¹˜ ê²€ì¦"""
        thresholds = get_performance_thresholds()
        validation_results = {
            "passed": True,
            "violations": [],
            "scores": {}
        }

        if "summary" not in results:
            validation_results["passed"] = False
            validation_results["violations"].append("í…ŒìŠ¤íŠ¸ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨")
            return validation_results

        summary = results["summary"]

        # ì‘ë‹µ ì‹œê°„ ê²€ì¦
        if summary.get("response_time_95p", 0) > thresholds["response_time_95p"]:
            validation_results["passed"] = False
            validation_results["violations"].append(
                f"95% ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: {summary['response_time_95p']}ms > {thresholds['response_time_95p']}ms"
            )

        # ì—ëŸ¬ìœ¨ ê²€ì¦
        total_requests = summary.get("requests_per_second", 0) * 60  # 1ë¶„ ê¸°ì¤€ ì¶”ì •
        if total_requests > 0:
            error_rate = summary.get("failures_per_second", 0) / summary.get("requests_per_second", 1)
            if error_rate > thresholds["error_rate"]:
                validation_results["passed"] = False
                validation_results["violations"].append(
                    f"ì—ëŸ¬ìœ¨ ì´ˆê³¼: {error_rate:.1%} > {thresholds['error_rate']:.1%}"
                )

        # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
        validation_results["scores"] = {
            "response_time_score": min(100, 5000 / max(summary.get("response_time_95p", 1), 1)),
            "throughput_score": min(100, summary.get("requests_per_second", 0) * 2),
            "reliability_score": max(0, 100 - (error_rate * 100)) if 'error_rate' in locals() else 100
        }

        return validation_results

    def save_results(self, scenario_name: str, results: Dict[str, Any], validation: Dict[str, Any]):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{scenario_name}_{timestamp}.json"
        filepath = self.results_dir / filename

        report_data = {
            "scenario": scenario_name,
            "timestamp": datetime.now().isoformat(),
            "backend_url": self.backend_url,
            "results": results,
            "validation": validation,
            "performance_thresholds": get_performance_thresholds()
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {filepath}")
        return filepath

    def generate_report(self, results_file: Path) -> str:
        """HTML ë³´ê³ ì„œ ìƒì„±"""
        with open(results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ - {data['scenario']}</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                .header {{ background: #f0f0f0; padding: 20px; border-radius: 5px; }}
                .metrics {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0; }}
                .metric {{ background: white; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}
                .metric.pass {{ border-color: #4CAF50; }}
                .metric.fail {{ border-color: #f44336; }}
                .score {{ font-size: 24px; font-weight: bold; }}
                .violations {{ background: #ffebee; padding: 15px; border-radius: 5px; margin: 20px 0; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ</h1>
                <p><strong>ì‹œë‚˜ë¦¬ì˜¤:</strong> {data['scenario']}</p>
                <p><strong>ì‹¤í–‰ ì‹œê°„:</strong> {data['timestamp']}</p>
                <p><strong>ë°±ì—”ë“œ URL:</strong> {data['backend_url']}</p>
            </div>

            <h2>ì„±ëŠ¥ ë©”íŠ¸ë¦­</h2>
            <div class="metrics">
        """

        summary = data.get('results', {}).get('summary', {})

        metrics = [
            ("ì‘ë‹µ ì‹œê°„ (95p)", f"{summary.get('response_time_95p', 0)}ms", "response_time_95p"),
            ("ì´ˆë‹¹ ìš”ì²­ ìˆ˜", f"{summary.get('requests_per_second', 0):.1f}", "requests_per_second"),
            ("ì‹¤íŒ¨ìœ¨", f"{summary.get('failures_per_second', 0):.3f}/s", "failures_per_second")
        ]

        thresholds = data.get('performance_thresholds', {})

        for name, value, key in metrics:
            status_class = "pass"
            if key == "response_time_95p" and summary.get(key, 0) > thresholds.get("response_time_95p", 2000):
                status_class = "fail"
            elif key == "failures_per_second" and summary.get(key, 0) > 0:
                status_class = "fail"

            html_content += f"""
                <div class="metric {status_class}">
                    <h3>{name}</h3>
                    <div class="score">{value}</div>
                </div>
            """

        html_content += """
            </div>

            <h2>ì„±ëŠ¥ ì ìˆ˜</h2>
            <div class="metrics">
        """

        scores = data.get('validation', {}).get('scores', {})
        for score_name, score_value in scores.items():
            html_content += f"""
                <div class="metric pass">
                    <h3>{score_name.replace('_', ' ').title()}</h3>
                    <div class="score">{score_value:.1f}</div>
                </div>
            """

        html_content += """
            </div>
        """

        violations = data.get('validation', {}).get('violations', [])
        if violations:
            html_content += """
                <div class="violations">
                    <h2>ğŸš¨ ì„±ëŠ¥ ê¸°ì¤€ ìœ„ë°˜ ì‚¬í•­</h2>
                    <ul>
            """
            for violation in violations:
                html_content += f"<li>{violation}</li>"
            html_content += "</ul></div>"

        html_content += """
        </body>
        </html>
        """

        report_file = results_file.with_suffix('.html')
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"ğŸ“ˆ HTML ë³´ê³ ì„œ ìƒì„±: {report_file}")
        return str(report_file)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description="ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ë¶„ì„ API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    parser.add_argument(
        "--scenario",
        choices=list(TEST_SCENARIOS.keys()),
        default="normal_load",
        help="ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤"
    )
    parser.add_argument(
        "--backend-url",
        default="http://localhost:8000",
        help="ë°±ì—”ë“œ ì„œë²„ URL"
    )
    parser.add_argument(
        "--generate-report",
        action="store_true",
        help="HTML ë³´ê³ ì„œ ìƒì„±"
    )
    parser.add_argument(
        "--all-scenarios",
        action="store_true",
        help="ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"
    )

    args = parser.parse_args()

    runner = PerformanceTestRunner(args.backend_url)

    if args.all_scenarios:
        print("ğŸ”„ ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
        all_results = {}

        for scenario_name in TEST_SCENARIOS.keys():
            try:
                results = runner.run_scenario(scenario_name)
                validation = runner.validate_performance(results)
                runner.save_results(scenario_name, results, validation)

                all_results[scenario_name] = {
                    "results": results,
                    "validation": validation
                }

                status = "âœ… í†µê³¼" if validation["passed"] else "âŒ ì‹¤íŒ¨"
                print(f"{scenario_name}: {status}")

            except Exception as e:
                print(f"âŒ {scenario_name} ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                all_results[scenario_name] = {"error": str(e)}

        # ì „ì²´ ìš”ì•½ ì¶œë ¥
        print("\nğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ìš”ì•½:")
        for scenario, result in all_results.items():
            if "error" in result:
                print(f"  {scenario}: âŒ ì˜¤ë¥˜ - {result['error']}")
            else:
                passed = result['validation']['passed']
                status = "âœ… í†µê³¼" if passed else "âŒ ì‹¤íŒ¨"
                score = result['validation']['scores'].get('response_time_score', 0)
                print(".1f"
        if args.generate_report:
            print("\nğŸ“ˆ ê°œë³„ HTML ë³´ê³ ì„œë“¤ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

    else:
        # ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
        try:
            results = runner.run_scenario(args.scenario)
            validation = runner.validate_performance(results)
            results_file = runner.save_results(args.scenario, results, validation)

            print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
            print(f"ì‹œë‚˜ë¦¬ì˜¤: {args.scenario}")
            print(f"ìƒíƒœ: {'âœ… í†µê³¼' if validation['passed'] else 'âŒ ì‹¤íŒ¨'}")

            if validation['violations']:
                print("ğŸš¨ ìœ„ë°˜ ì‚¬í•­:")
                for violation in validation['violations']:
                    print(f"  - {violation}")

            if args.generate_report:
                report_file = runner.generate_report(Path(results_file))
                print(f"ğŸ“ˆ HTML ë³´ê³ ì„œ: {report_file}")

        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            sys.exit(1)


if __name__ == "__main__":
    main()


