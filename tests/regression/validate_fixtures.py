"""
íšŒê·€ í…ŒìŠ¤íŠ¸ í”½ìŠ¤ì²˜ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” íšŒê·€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ë¬´ê²°ì„±ê³¼ ì¼ê´€ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦, ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬, íŒŒì¼ êµ¬ì¡° ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

Author: Choi Algorithm Regression Test Team
Created: 2025-09-20
"""

import json
import logging
from pathlib import Path
from typing import Dict, Any, List, Tuple
import jsonschema
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class RegressionFixtureValidator:
    """
    íšŒê·€ í…ŒìŠ¤íŠ¸ í”½ìŠ¤ì²˜ ê²€ì¦ê¸°
    
    JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦, ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬, íŒŒì¼ êµ¬ì¡° ì¼ê´€ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ê²€ì¦ê¸° ì´ˆê¸°í™”"""
        self.data_dir = Path(__file__).parent / "data"
        self.schema_file = self.data_dir / "validation_schema.json"
        
        # JSON ìŠ¤í‚¤ë§ˆ ë¡œë“œ
        with open(self.schema_file, 'r', encoding='utf-8') as f:
            self.validation_schema = json.load(f)
        
        self.validation_errors = []
        self.warnings = []
        
        logger.info("Regression fixture validator initialized")
    
    def validate_all_fixtures(self) -> bool:
        """ëª¨ë“  í”½ìŠ¤ì²˜ ê²€ì¦"""
        try:
            logger.info("Starting comprehensive fixture validation")
            
            # 1. ë””ë ‰í† ë¦¬ êµ¬ì¡° ê²€ì¦
            self._validate_directory_structure()
            
            # 2. ê°œë³„ í”½ìŠ¤ì²˜ ê²€ì¦
            self._validate_individual_fixtures()
            
            # 3. í”½ìŠ¤ì²˜ ê°„ ì¼ê´€ì„± ê²€ì¦
            self._validate_cross_fixture_consistency()
            
            # 4. ë°ì´í„° í’ˆì§ˆ ê²€ì¦
            self._validate_data_quality()
            
            # ê²°ê³¼ ë³´ê³ 
            self._report_validation_results()
            
            return len(self.validation_errors) == 0
            
        except Exception as e:
            logger.error(f"Validation process failed: {e}")
            return False
    
    def _validate_directory_structure(self) -> None:
        """ë””ë ‰í† ë¦¬ êµ¬ì¡° ê²€ì¦"""
        logger.info("Validating directory structure")
        
        expected_dirs = ["normal_cases", "edge_cases", "abnormal_triggers", "boundary_conditions"]
        
        for dir_name in expected_dirs:
            dir_path = self.data_dir / dir_name
            if not dir_path.exists():
                self.validation_errors.append(f"Missing directory: {dir_name}")
            elif not dir_path.is_dir():
                self.validation_errors.append(f"Not a directory: {dir_name}")
        
        logger.info("Directory structure validation completed")
    
    def _validate_individual_fixtures(self) -> None:
        """ê°œë³„ í”½ìŠ¤ì²˜ ê²€ì¦"""
        logger.info("Validating individual fixtures")
        
        input_files = list(self.data_dir.rglob("*_input.json"))
        
        for input_file in input_files:
            try:
                self._validate_single_fixture(input_file)
            except Exception as e:
                self.validation_errors.append(f"Error validating {input_file.name}: {e}")
        
        logger.info(f"Individual fixture validation completed: {len(input_files)} files")
    
    def _validate_single_fixture(self, input_file: Path) -> None:
        """ë‹¨ì¼ í”½ìŠ¤ì²˜ ê²€ì¦"""
        # JSON ë¡œë“œ ë° ìŠ¤í‚¤ë§ˆ ê²€ì¦
        with open(input_file, 'r', encoding='utf-8') as f:
            fixture_data = json.load(f)
        
        try:
            jsonschema.validate(fixture_data, self.validation_schema)
        except jsonschema.ValidationError as e:
            self.validation_errors.append(f"{input_file.name}: Schema validation failed - {e.message}")
            return
        
        # ëŒ€ì‘í•˜ëŠ” ì˜ˆìƒ ì¶œë ¥ íŒŒì¼ í™•ì¸
        expected_file = input_file.parent / input_file.name.replace("_input.json", "_expected.json")
        if not expected_file.exists():
            self.warnings.append(f"{input_file.name}: Missing expected output file")
        
        # ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
        self._validate_fixture_data_consistency(fixture_data, input_file.name)
    
    def _validate_fixture_data_consistency(self, data: Dict[str, Any], filename: str) -> None:
        """í”½ìŠ¤ì²˜ ë°ì´í„° ì¼ê´€ì„± ê²€ì¦"""
        # cell_idsì™€ peg_data í‚¤ ì¼ì¹˜ í™•ì¸
        cell_ids = set(data["cell_ids"])
        peg_data_keys = set(data["peg_data"].keys())
        
        if cell_ids != peg_data_keys:
            self.validation_errors.append(
                f"{filename}: cell_ids {cell_ids} != peg_data keys {peg_data_keys}"
            )
        
        # PEG ë°ì´í„° ë‚´ë¶€ ì¼ê´€ì„± í™•ì¸
        for cell_id, peg_list in data["peg_data"].items():
            for peg_info in peg_list:
                if peg_info["cell_id"] != cell_id:
                    self.validation_errors.append(
                        f"{filename}: PEG cell_id mismatch in {cell_id}"
                    )
                
                # ìƒ˜í”Œ ê¸¸ì´ ê²€ì¦
                pre_len = len(peg_info["pre_samples"])
                post_len = len(peg_info["post_samples"])
                
                if pre_len == 0 or post_len == 0:
                    self.validation_errors.append(
                        f"{filename}: Empty samples in {cell_id}/{peg_info['peg_name']}"
                    )
                
                if abs(pre_len - post_len) > pre_len * 0.5:  # 50% ì´ìƒ ì°¨ì´
                    self.warnings.append(
                        f"{filename}: Large sample count difference in {cell_id}/{peg_info['peg_name']}"
                    )
    
    def _validate_cross_fixture_consistency(self) -> None:
        """í”½ìŠ¤ì²˜ ê°„ ì¼ê´€ì„± ê²€ì¦"""
        logger.info("Validating cross-fixture consistency")
        
        # ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„ ì¤‘ë³µ í™•ì¸
        scenario_names = []
        input_files = list(self.data_dir.rglob("*_input.json"))
        
        for input_file in input_files:
            try:
                with open(input_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    scenario_name = data.get("scenario_name")
                    if scenario_name in scenario_names:
                        self.validation_errors.append(f"Duplicate scenario name: {scenario_name}")
                    scenario_names.append(scenario_name)
            except Exception as e:
                self.validation_errors.append(f"Error reading {input_file.name}: {e}")
        
        logger.info("Cross-fixture consistency validation completed")
    
    def _validate_data_quality(self) -> None:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
        logger.info("Validating data quality")
        
        input_files = list(self.data_dir.rglob("*_input.json"))
        
        for input_file in input_files:
            try:
                with open(input_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                self._check_data_quality_metrics(data, input_file.name)
                
            except Exception as e:
                self.validation_errors.append(f"Data quality check failed for {input_file.name}: {e}")
        
        logger.info("Data quality validation completed")
    
    def _check_data_quality_metrics(self, data: Dict[str, Any], filename: str) -> None:
        """ë°ì´í„° í’ˆì§ˆ ì§€í‘œ ê²€ì¦"""
        for cell_id, peg_list in data["peg_data"].items():
            for peg_info in peg_list:
                pre_samples = [x for x in peg_info["pre_samples"] if x is not None]
                post_samples = [x for x in peg_info["post_samples"] if x is not None]
                
                # ND ë¹„ìœ¨ ê²€ì¦
                total_pre = len(peg_info["pre_samples"])
                total_post = len(peg_info["post_samples"])
                nd_ratio_pre = (total_pre - len(pre_samples)) / total_pre if total_pre > 0 else 0
                nd_ratio_post = (total_post - len(post_samples)) / total_post if total_post > 0 else 0
                
                if nd_ratio_pre > 0.8 or nd_ratio_post > 0.8:
                    self.warnings.append(
                        f"{filename}: High ND ratio in {cell_id}/{peg_info['peg_name']}"
                    )
                
                # ê°’ì˜ ë²”ìœ„ ê²€ì¦ (ìŒìˆ˜ ê°’ í™•ì¸)
                all_values = pre_samples + post_samples
                if any(x < 0 for x in all_values):
                    self.warnings.append(
                        f"{filename}: Negative values in {cell_id}/{peg_info['peg_name']}"
                    )
                
                # ê·¹í•œê°’ í™•ì¸
                if all_values and (max(all_values) > 1e6 or max(all_values) < 1e-6):
                    self.warnings.append(
                        f"{filename}: Extreme values in {cell_id}/{peg_info['peg_name']}"
                    )
    
    def _report_validation_results(self) -> None:
        """ê²€ì¦ ê²°ê³¼ ë³´ê³ """
        print("\n" + "=" * 60)
        print("ğŸ” íšŒê·€ í…ŒìŠ¤íŠ¸ í”½ìŠ¤ì²˜ ê²€ì¦ ê²°ê³¼")
        print("=" * 60)
        
        if not self.validation_errors and not self.warnings:
            print("âœ… ëª¨ë“  ê²€ì¦ í†µê³¼! í”½ìŠ¤ì²˜ ë°ì´í„°ê°€ ì™„ë²½í•©ë‹ˆë‹¤.")
        else:
            if self.validation_errors:
                print(f"âŒ ê²€ì¦ ì˜¤ë¥˜: {len(self.validation_errors)}ê°œ")
                for i, error in enumerate(self.validation_errors, 1):
                    print(f"   {i}. {error}")
            
            if self.warnings:
                print(f"âš ï¸ ê²½ê³ : {len(self.warnings)}ê°œ")
                for i, warning in enumerate(self.warnings, 1):
                    print(f"   {i}. {warning}")
        
        print("=" * 60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print("ğŸ” Choi ì•Œê³ ë¦¬ì¦˜ íšŒê·€ í…ŒìŠ¤íŠ¸ í”½ìŠ¤ì²˜ ê²€ì¦")
        
        validator = RegressionFixtureValidator()
        is_valid = validator.validate_all_fixtures()
        
        if is_valid:
            print("ğŸ‰ ëª¨ë“  í”½ìŠ¤ì²˜ ê²€ì¦ ì„±ê³µ!")
            sys.exit(0)
        else:
            print("âŒ í”½ìŠ¤ì²˜ ê²€ì¦ ì‹¤íŒ¨")
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
